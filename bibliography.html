<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research Guides - AI and Judaism Resource Library</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <link rel="icon" type="image/svg" href="/favicon.svg">
    <link rel="icon" type="image/png" href="/favicon.png">
    
    <style>
        body { background-color: #f8f9fa; color: #333; }
        :root {
            --sb-blue: #4C72B0;
            --sb-orange: #DD8452;
            --sb-green: #55A868;
        }
        
        html { scroll-behavior: smooth; }
        
        /* Entry button states */
        .entry-btn {
            transition: all 0.2s ease;
        }
        
        .entry-btn.active {
            background-color: var(--sb-blue);
            color: white;
        }
        
        .entry-btn:not(.active):hover {
            background-color: #dbeafe;
        }
        
        /* Reading pane */
        .reading-pane {
            opacity: 0;
            max-height: 0;
            overflow: hidden;
            transition: opacity 0.3s ease, max-height 0.3s ease;
        }
        
        .reading-pane.visible {
            opacity: 1;
            max-height: none;
            overflow: visible;
        }
        
        /* Search results */
        .search-results {
            display: none;
        }
        
        .search-results.visible {
            display: block;
        }
        
        .search-result-table {
            cursor: pointer;
            transition: all 0.2s ease;
        }
        
        .search-result-table:hover {
            border-color: var(--sb-blue);
            box-shadow: 0 2px 8px rgba(76, 114, 176, 0.15);
        }
        
        /* Search highlight */
        .search-highlight {
            background-color: #fef08a;
            padding: 0 2px;
            border-radius: 2px;
        }
        
        /* Typography for reading */
        .entry-content {
            font-size: 1rem;
            line-height: 1.75;
        }
        
        .entry-content h4 {
            font-size: 1.1rem;
            font-weight: 600;
            margin-top: 2rem;
            margin-bottom: 0.75rem;
            color: #1f2937;
        }
        
        .entry-content p {
            margin-bottom: 1rem;
        }
        
        .entry-content ul {
            margin-bottom: 1rem;
        }
        
        .entry-content li {
            margin-bottom: 0.5rem;
        }
    </style>
</head>
<body class="bg-gray-50 text-gray-900 font-sans">

    <div class="h-screen flex flex-col">
        <!-- Main Navigation -->
        <nav class="bg-white border-b border-gray-200 px-6 py-4 flex items-center gap-8 text-sm font-medium z-40">
            <a href="index.html" class="text-gray-500 hover:text-gray-900 transition-colors">Home</a>
            <a href="about.html" class="text-gray-500 hover:text-gray-900 transition-colors">About</a>
            <a href="table.html" class="text-gray-500 hover:text-gray-900 transition-colors">Internet Index</a>
            <a href="*" class="text-blue-600 font-bold border-b-2 border-blue-600 pb-0.5">Research Guides</a>
        </nav>
                
        <!-- Sub Navigation with Search -->
        <nav class="bg-white border-b border-gray-200 px-6 py-4 flex items-center gap-8 text-sm font-medium z-40">
            <a href="bibliography.html" class="text-xl font-bold tracking-tight border-b-2 border-blue-600 pb-0.5">All Research Guides</a>
            <a href="primary-sources.html" class="text-gray-500 hover:text-blue-600 transition-colors">Index of Primary Sources</a>
            <a href="sec-sources.html" class="text-gray-500 hover:text-blue-600 transition-colors">Index of Secondary Sources</a>
            
            <div class="flex items-center gap-3 w-full md:w-auto ml-auto">
                <div class="relative flex-1 md:w-80">
                    <input type="text" id="searchInput" placeholder="Search entries..." 
                        class="w-full px-3 py-1.5 pl-9 text-sm border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500 focus:border-transparent">
                    <i class="fas fa-search absolute left-3 top-1/2 transform -translate-y-1/2 text-gray-400 text-sm"></i>
                    <button id="clearSearch" class="absolute right-3 top-1/2 transform -translate-y-1/2 text-gray-400 hover:text-gray-600 hidden">
                        <i class="fas fa-times text-sm"></i>
                    </button>
                </div>
            </div>
        </nav>            

        <main class="flex-1 overflow-y-auto">
            <div class="max-w-7xl mx-auto">
                
                <div class="px-6 pt-8 pb-12">
                    
                    <!-- Introduction -->
                    <div class="max-w-4xl mb-8 text-gray-700 text-base leading-relaxed">
                        <p class="mb-4">
                            These research guides provide in-depth explorations of key topics at the intersection of artificial intelligence and Jewish thought. 
                            Each entry serves as both a mini encyclopedia article and an annotated bibliography. 
                            Each entry is also associated with a Sefaria Source Sheet of primary sources that may be relevant to the question.
                            Together these should help offer context, analysis, and resources for further studies. 
                            As always, be sure to <a href="/cdn-cgi/l/email-protection#f5819d90879c869d9a9b9c98b59298949c99db969a98" class="text-blue-600">contact us</a> with any feedback and/or additional resources you'd like to see here.
                            </p>
                        <p class="mb-6">
                            Click on any topic below to read its full entry, or use the search bar (top right) to find specific terms across all entries.
                        </p>
                    </div>

                    <!-- Entry Buttons -->
                    <div id="entryButtons" class="mb-8 flex flex-wrap gap-2">
                        <button data-entry="agency" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Agency (Sheliḥut)</button>
                        <button data-entry="algorithmic-pricing" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Algorithmic Pricing</button>
                        <button data-entry="alignment" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Alignment and Control Problem</button>
                        <button data-entry="angels" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Angels, Demons, and Monsters</button>
                        <button data-entry="animals" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Animals</button>
                        <button data-entry="antisemitism" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Anti-Semitism (and AI)</button>
                        <button data-entry="autonomous-vehicles" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Autonomous Vehicles and the Trolley Problem</button>
                        <button data-entry="autonomous-weapons" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Autonomous Weapons Systems</button>
                        <button data-entry="bias" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Bias and Discrimination</button>
                        <button data-entry="bci" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Brain-Computer Interface Devices</button>
                        <button data-entry="care" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Childcare and Elder Care</button>
                        <button data-entry="cbrn" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Catastrophic and CBRN Risk</button>
                        <button data-entry="liability" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Civil Liability for AI-Caused Harm</button>
                        <button data-entry="commandments" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Commandments, Fulfillment Through AI</button>
                        <button data-entry="consciousness" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Consciousness and Minds</button>
                        <button data-entry="quorum" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Counting for a Quorum</button>
                        <button data-entry="creation" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Creation</button>
                        <button data-entry="economic" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Economic Disruption and Job Displacement</button>
                        <button data-entry="existential" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Existential Risks</button>
                        <button data-entry="freewill" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Free Will</button>
                        <button data-entry="futurism" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Futurism/Forecasting</button>
                        <button data-entry="golem" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Golems</button>
                        <button data-entry="psak" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Halakhic Decision-Making</button>
                        <button data-entry="humans" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Human Souls and Minds</button>
                        <button data-entry="idolatry" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Idolatry</button>
                        <button data-entry="grama" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Indirect Causation (Grama) and AI</button>
                        <button data-entry="intentionality" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Intentionality</button>
                        <button data-entry="ip" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Intellectual Property</button>
                        <button data-entry="jewishscifi" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Jewish Science Fiction</button>
                        <button data-entry="magic" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Magic</button>
                        <button data-entry="manipulation" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Manipulation</button>
                        <button data-entry="medicine" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Medicine and Artificial Intelligence</button>
                        <button data-entry="murder" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Murder of Artificially Created Beings</button>
                        <button data-entry="obligations" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Obligations of Artificially Created Beings</button>
                        <button data-entry="printing" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Printing Press</button>
                        <button data-entry="privacy" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Privacy and Surveillance</button>
                        <button data-entry="resurrection" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Resurrection</button>
                        <button data-entry="sexbots" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Sexbots and AI Romantic Partners</button>
                        <button data-entry="shabbat" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Shabbat</button>
                        <button data-entry="social-media" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Social Media and Psychological Vulnerabilities</button>
                        <button data-entry="technology" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Technology and Judaism</button>
                        <button data-entry="testimony" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Testimony and Witness Capacity</button>
                        <button data-entry="torahstudy" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Torah Study</button>
                        <button data-entry="transhumanism" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Transhumanism</button>
                        <button data-entry="truth" class="entry-btn px-3 py-1.5 bg-blue-100 text-blue-700 rounded-md text-sm font-medium">Truth</button>
 
                    </div>
                    
                    <!-- Search Results Area (hidden by default) -->
                    <div id="searchResults" class="search-results max-w-4xl mb-8">
                        <p id="searchResultsCount" class="text-sm text-gray-600 mb-4"></p>
                        <div id="searchResultsList" class="space-y-4"></div>
                    </div>
                    
                    <!-- Reading Pane -->
                    <div id="readingPane" class="reading-pane max-w-4xl">
                        <div class="bg-white rounded-lg shadow-sm border border-gray-200 p-8">
                            <h2 id="entryTitle" class="text-2xl font-bold text-gray-900 mb-2"></h2>
                            <p id="entryCrossRefs" class="italic text-gray-500 mb-6"></p>
                            <div id="entryContent" class="entry-content text-gray-700"></div>
                        </div>
                    </div>
                    
                    <!-- Hidden Entry Data -->
                    <div id="entryData" class="hidden">
                        <!-- Agency Entry -->
                        <div data-entry-id="agency" data-entry-title="Agency (Sheliḥut) and AI" data-entry-crossrefs="See also: Commandments, Fulfillment Through AI; Civil Liability for AI-Caused Harm; Indirect Causation (Grama) and AI; Intentionality">
                            <h4>Overview</h4>
                            <p>
                                <em>Sheliḥut</em> (agency) is the halakhic framework by which one person may act on behalf of another. The principle, phrased by the Talmud as "a person's agent is like himself" (שלחו של אדם כמותו, <em>sheluḥo shel adam ke-moto</em>; Berakhot 34b; Kiddushin 41b), allows legally binding actions performed by an agent proxy (<em>shaliaḥ</em>) to be attributed to the principal (<em>meshaleaḥ</em>). This framework governs commercial transactions, marriage contracts, and even some but not all ritual obligations. 
                            </p>
                            <p>    
                                The matter of <em>sheliḥut</em> raises the question of whether autonomous or semi-autonomous nonhuman systems can serve as halakhic agents, and whether their actions can be meaningfully attributed to human principals. When it comes to ritual fulfillment of commandments, at least, application to AI is constrained by a fundamental requirement: only one who is <em>bar ḥiyuva</em> (subject to legal obligation) can serve as an agent. Presumably, since an AI is not commanded to observe mitzvot, then under classic halakhic reasoning, “objects can never be proxies” (Kalman 2024). 
                            </p>
                            <p>
                                However, it is possible that this limitation is applicable only to ritual commandments; in fact, the Talmud does suggest some equivalence or at least a comparison between a person’s agent and their courtyard, which is able to legally acquire property for its owner within its domain (Bava Metzia 10b-11b, Sefer ha-Mikneh 15:4-8). 
                                Medieval and modern commentators have discussed to what extent, if any, the rabbis extend the legal principle of shelihut to this specific inanimate object, vis. a person’s real property (Tosafot Rosh and Rashba to Kiddushin 42a). 
                                While minors and the mentally incompetent are precluded from serving as valid agents due to their insufficient <em>da’at</em> (knowledge or intent), the terminology of <em>sheliḥut</em> used in the context of property indicates some flexibility for applications which are sufficiently dissimilar from human examples (cf. Nimukei Yosef and Pnei Yehoshua to Bava Metzia 11a).
                            </p>
                            <p>
                                Whether or not any vestige of the halakhic concept of <em>sheliḥut</em> applies to artificially constructed agents, the extensive literature on this topic from traditional sources may prove useful for developing theories of AI liability and similar issues. 
                                For example, the Talmudic (Gittin 29a-b) discusses the case of a principal (specifically, a husband seeking to divorce his wife) who dies before the agent has discharged his duty, and the ensuing discourse shows how halakhic authorities have considered to what extent the principal must be continuously ‘interested’ (even subconsciously) in the agency of his proxy and how completely authority may have been transferred from one person to the other (Klein 2024).
                            </p>
                            <h4>Primary Sources</h4>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Babylonian Talmud: Berakhot 34b; Gittin 29a-b; Kiddushin 41b; Bava Metzia 10a-11b.</strong>
                                    </p>
                                <li>
                                    <p>
                                        <strong>Ketzot HaḤoshen, siman 182, 188.</strong> and <strong>Sefer ha-Mikneh 15:4-8.</strong> Key discussions of the nature of agency and the authority transferred to agents; analyzes whether the agent acts as an extension of the principal or with independently delegated power.
                                    </p>
                                </li>
                            </ul>
                            <h4>Secondary Sources</h4>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Klein, Dov.</strong> "Mingnon HaSheliḥut." [Hebrew] <em>Yarhon Ha-Otzar</em> 105 (2024): 449-464. Extensive treatment of the conceptual underpinnings of <em>shelihut</em> through rabbinic literature; briefly but directly addresses whether AI can fit within these frameworks.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Kalman, David Zvi.</strong> "Artificial Intelligence and Jewish Thought." In <em>The Cambridge Companion to Religion and Artificial Intelligence</em> (2024): 69-87. Argues that <em>sheliḥut</em>, animal-liability, and <em>grama</em> frameworks appear applicable to AI but remain underdetermined; cautions against premature systematization.
                                    </p>
                                </li>
                            </ul>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Bias Entry -->
                        <div data-entry-id="bias" data-entry-title="Bias and Discrimination" data-entry-crossrefs="See also: Anti-Semitism (and AI); Truth; AI Ethics">
                            <h4>Overview</h4>
                            <p>
                                Can AI systems be trained to avoid perpetuating or amplifying social biases, and if debiasing efforts risk falsifying historical data, how should we balance accuracy against harm? AI systems trained on historical data inevitably encode the biases present in that data, raising difficult questions about whether and how to intervene. Debiasing techniques may improve fairness in outputs but risk distorting the historical record or creating systems that are less accurate in certain contexts. Jewish ethical frameworks that emphasize both truth (<em>emet</em>) and justice (<em>tzedek</em>) may offer resources for navigating these tensions.
                            </p>
                            <h4>Secondary Sources</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Algorithmic Pricing Entry -->
                        <div data-entry-id="algorithmic-pricing" data-entry-title="Algorithmic Pricing" data-entry-crossrefs="See also: Civil Liability for AI-Caused Harm; Economic Disruption and Job Displacement; Manipulation; Privacy and Surveillance; Technology and Judaism (General)">
                            <h4>Overview</h4>
                            <p>
                                Algorithmic pricing refers to the use of automated systems, including machine learning models, to set prices dynamically based on data about consumers, market conditions, inventory levels, and competitor behavior. While such systems can improve economic efficiency and market responsiveness, they raise ethical concerns when they enable forms of price discrimination, especially if those come about through methods that would be impossible for humans to implement or to understand, such that no human has an awareness of the factors that determine the specific price changes. 
                            </p>
                            <p>
                                Typically, Jewish law sees no problem in charging or offering different prices for different buyers and sellers, but there is a large body of literature on fair pricing of market transactions. The Talmud takes a very harsh view against "artificial" price manipulation (Bava Batra 90b; cf. Warhaftig 1987). Legal traditions addressing <em>ona'ah</em> (price fraud/overpricing), <em>hafka'at she'arim</em> (profiteering on essential goods), and communal regulation offer frameworks for evaluating these practices. The halakhic concern with pricing fairness emerges from several related but distinct sources. The Biblical prohibition of <em>ona'ah</em> (Leviticus 25:14) prohibits transactions where the price deviates more than one-sixth from the market price, protecting both buyers and sellers from exploitation through information asymmetry. The Rabbinic ordinance of <em>hafka'at she'arim</em> limits profit margins on essential foodstuffs (<em>hayyei nefesh</em>) reflects concern for ensuring access to necessities. Additionally, the corporate Jewish community possessed authority to regulate prices and wages relatively democratically, with enforcement power backed by penalties and according to some, even police monitors (Bava Batra, Babylonian Talmud 89a and Jerusalem Talmud 5:5). 
                            </p>
                            <p>
                                Applying these rabbinic laws to modern markets, even without consideration of technological advancement in the quantification of market parameters, is not trivial. One consideration is that rabbinic concerns may seem to be, at least on their face, opposed to free market ideals and other principles of modern economic theory (Rakover 2000, Makovi 2016). The scholarly literature reveals some debate about whether these halakhic frameworks constitute "price controls" in the economic sense and whether they remain applicable in modern market conditions (Levine 2012, Makovi 2016).
                            </p>
                            <p>
                                When it comes to price discrimination, it should be noted that the Talmud itself endorses certain forms of differential pricing based on status. Torah scholars (<em>talmidei hakhamim</em>) received special market privileges, including priority to sell their goods first and exemption from restrictions that applied to other traveling merchants (Bava Batra 22a). Jewish tradition does not consider differential treatment as inherently problematic; the legitimacy of preferential pricing depends on whether the basis for differentiation serves a recognized social good (such as supporting Torah study). It is possible that other considerations, such as economic efficiency and supply chain robustness may also constitute sufficient cause for price discrimination. It is also possible that a level of transparency of algorithmic (or AI-assisted) market decisions may be necessary in order to be legitimately relied upon, just as community regulations were typically conducted by deliberations of human leaders. But all of these questions remain largely unexplored.
                            </p>
                            <h4>Primary Sources</h4>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Leviticus 25:14.</strong> The Biblical source for <em>ona'ah</em>.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Mishnah Bava Metzia 4:3-12 and Babylonian Talmud Bava Metzia 40b; Bava Batra 89a-91a.</strong> Discusses market supervision, price commissioners, profit limitations on essential goods, and restrictions on speculation and hoarding.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Tosefta Bava Metzia 11:12 (also 11:23).</strong> "The townspeople may stipulate prices, measures, and the wages of workers. They are permitted to impose penalties."
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Maimonides, Mishneh Torah, Hilkhot Mekhira 12-14.</strong> Codifies the laws of <em>ona'ah</em> (chapters 12-13) and market regulation (chapter 14).
                                    </p>
                                </li>
                            </ul>
                            <h4>Secondary Sources</h4>
                            <p>
                                <strong><em>Conceptual Foundations</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Kleiman, Ephraim.</strong> "'Just Price' in Talmudic Literature." <em>History of Political Economy</em> 19, no. 1 (1987): 23-45. Foundational study arguing that <em>ona'ah</em> is not a price control but a protection against asymmetric information; possibly relevant to cases of inscrutable algorithms.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Rakover, Nahum.</strong> "Price Regulation in Jewish Law." In <em>Ethics in the Market Place: A Jewish Perspective</em>. Jerusalem: Library of Jewish Law, 2000. Accessible summary of Talmudic debates about price supervision.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Tamari, Meir.</strong> <em>In the Marketplace: Jewish Business Ethics.</em> Southfield, MI: Targum/Feldheim, 1991. Accessible presentation on <em>halakhot</em> of market economics, arguing for the relevance even of the enforcement of such laws in modern economies.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Warhaftig, Itamar.</strong> "Consumer Protection: Price and Wage Levels." <em>Crossroads: Halacha and the Modern World</em>, Vol. 1. Alon Shvut-Gush Etzion: Zomet Institute, 1987. Detailed analysis of <em>hafka'at she'arim</em> and prohibitions of "artificial" market manipulation or price inflation, also emphasizing the importance of limiting profit margins.
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>Economic Analysis</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Levine, Aaron.</strong> <em>Economic Morality and Jewish Law.</em> Oxford: Oxford University Press, 2012. Chapter 4 ("Price Controls in Jewish Law"). Recognizing that modern economic theory holds that external price regulations are self-defeating, Levine argues that halakha is not interested in price controls in the strictly economic sense.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Makovi, Michael.</strong> "Price-Controls in Jewish Law." MPRA Paper No. 72821, 2016. Critical analysis from a free-market economic perspective.
                                    </p>
                                </li>
                            </ul>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Alignment Entry -->
                        <div data-entry-id="alignment" data-entry-title="Alignment and Control Problem" data-entry-crossrefs="See also: Angels, Demons, and Monsters; Creation; Existential Risks; Golems">
                            <h4>Overview</h4>
                            <p>
                                In contemporary discourse around Artificial Intelligence, the "alignment problem" refers to the challenge of ensuring that artificial intelligence systems reliably act in accordance with human values and intentions. Sometimes this is phrased differently, as a "control" question, which asks whether humans can maintain meaningful oversight of AI systems, particularly as they become more capable and more inscrutable. These intertwined concerns have emerged as central preoccupations of contemporary AI ethics and safety research, and have spawned an active field of both technical AI safety and AI governance from a regulatory or political perspective (Christian 2020; Bostrom 2014; Dafoe 2018).
                            </p>
                            <p>
                                Jewish sources offer several frameworks for thinking about these problems, though none map perfectly onto contemporary AI. The most suggestive parallel may be the rabbinic discourse on <em>shedim</em> (demons) and the practice of demon-summoning. Unlike in Christian demonology, rabbinic demons are not inherently evil but are intelligent agents with their own interests and capacities for deception (Ronis 2022). In rabbinic literature, we find discussions about whether and how humans may consult with demons, and notably, a recognition that such entities are fundamentally unreliable (Shabbat 101a, Nahmanides to Shabbat 156).
                            </p>
                            <p>
                                Similar precedent arises from traditions of artificial humanoids; later called "Golems," a common trope regarding these creatures was their resistance to being fully controlled. Rabbi Yaakov Emden (18th c.) records that his ancestor, R. Eliyahu Ba'al Shem, fashioned such a being, but later destroyed his creation because "when the master saw that the Golem was growing larger and larger, he feared that the Golem would destroy the universe;" in the ensuing battle to subdue the creature, "the Golem injured him, scarring him on the face" (She'elat Ya'avetz 2:82). These and similar texts indicate that existential anxieties around the dangers of artificial humanoids are not new, and may point to the importance of maintaining controls over such technologies and the need to have an accessible "kill switch" if necessary. Of course, nearly all such discussions, even when they appear in Jewish legal texts, maintain more of a folkloristic than normative tone. It is unclear to what extent these rabbinic authors considered the control problem in more detail, and how they would determine what are acceptable and unacceptable levels of unpredictability or self-directed behavior in products of human artifice, but a careful reading of these sources may prove fruitful in that regard.
                            </p>
                            <h4>Primary Sources</h4>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>BT Sanhedrin 65b-67b; 101a.</strong>
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Nahmanides' responsum on Chaldeans and demons (printed at BT Shabbat 156).</strong>
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>She'elat Ya'avetz 2:82.</strong>
                                    </p>
                                </li>
                            </ul>
                            <h4>Secondary Sources</h4>
                            <p>
                                <strong><em>The Alignment Problem in AI</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Bostrom, Nick.</strong> <em>Superintelligence: Paths, Dangers, Strategies.</em> Oxford: Oxford University Press, 2014. One of the earliest and most influential statements of existential risk from advanced AI, including the "control problem" of maintaining human authority over superintelligent systems.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Christian, Brian.</strong> <em>The Alignment Problem: Machine Learning and Human Values.</em> New York: W. W. Norton, 2020. The definitive book on AI alignment through the modern history of Artificial Intelligence; a very accessible but highly detailed study.
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>Golem Traditions and the Control Problem</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Charpa, Ulrich.</strong> "Synthetic Biology and the Golem of Prague: Philosophical Reflections on a Suggestive Metaphor." <em>Perspectives in Biology and Medicine</em> 55, no. 4 (2012): 554-70. Examines the golem as a metaphor for emerging biotechnology; though focused on synthetic biology, the analysis of control anxieties transfers directly to AI.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Idel, Moshe.</strong> <em>Golem: Jewish Magical and Mystical Traditions on the Artificial Anthropoid.</em> Albany: SUNY Press, 1990. The definitive scholarly treatment of golem traditions; distinguishes between mystical-experiential and practical-magical interpretations and traces the development of control anxieties in later golem narratives.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Scholem, Gershom.</strong> "The Idea of the Golem." In <em>On the Kabbalah and Its Symbolism</em>, 158-204. New York: Schocken Books, 1965. Foundational essay on golem symbolism, including discussion of thirteenth-century German legends in which the golem warns against its own creation.
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>Jewish Demonology and Agent Reliability</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Ronis, Sara.</strong> <em>Demons in the Details: Demonic Discourse and Rabbinic Culture in Late Antique Babylonia.</em> University of California Press, 2022. The most comprehensive recent study of Babylonian Talmudic demonology; argues that demons served as a conceptual space for exploring boundaries and anxieties, directly applicable to understanding AI as a new liminal category.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Bohak, Gideon.</strong> <em>Ancient Jewish Magic: A History.</em> Cambridge: Cambridge University Press, 2008. Survey of Jewish magical practices including demon adjuration; useful for understanding the techniques by which practitioners attempted to bind and control supernatural entities.
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>AI and Contemporary Jewish Ethics</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Grossman, Yitzhak.</strong> "Jewish Perspectives on Artificial Intelligence and Synthetic Biology." <em>Ḥakirah</em> 35 (2024): 61-92. Surveys rabbinic sources on artificial creation, including the fear that golems might "become harmful to people" if left to grow; connects classical concerns to contemporary AI.
                                    </p>
                                </li>
                            </ul>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Angels Entry -->
                        <div data-entry-id="angels" data-entry-title="Angels, Demons, and Monsters" data-entry-crossrefs="See also: Animals; Free Will; Golems; Intentionality; Souls">
                            <h4>Overview</h4>
                            <p>
                                Jewish tradition recognized the existence of various non-human beings that nevertheless seem to possess many human-like characteristics, sometimes including intelligence, speech, and some personal agency. All of these are, in the traditional rabbinic conception, naturally occurring phenomena, as opposed to the *<a href="#golems"><strong>golem</strong></a>, which is a product of human artifice. Angels, demons, and other human-like creatures occupy varied positions in Jewish cosmology: angels (<em>mal&#39;akhim</em>, &quot;messengers&quot;) typically carry out divine will without physical needs or moral struggle; demons (<em>shedim</em>) in rabbinic literature share surprising affinities with humans, including mortality and subjection to divine law; and humanoid monsters blur the boundary between human and animal. Together, these categories reveal that Jewish thought has long grappled with what David Zvi Kalman calls the &quot;human gradient,&quot; the recognition that humanity is not a binary category and that intelligent or quasi-human beings need not threaten humanity&#39;s special status (Kalman 2024).
                            </p>
                            <p>
                                The very liminality of these creatures as not-quite-humans is made explicit by rabbinic sages. In BT <em>Hagigah</em> 16a for example, the sages note that demons possess six characteristics: three like ministering angels (wings, flight across the world, foreknowledge) and three like humans (eating, drinking, procreation, and death), and this schema is next applied to humans themselves, who have six traits, three in common with angels and three that are shared with animals. Such conversations recognize the possibility that humans possess a collection of capabilities, but the most “human” of the:namely, &quot;intelligence, posture, and holy speech” are shared by angels as well. The framework can be theoretically applied to Artificial Intelligence: it may not have “posture” (<em>me’halkhim be-kimah zekufah</em>) but does it have speech and/or intelligence (<em>da’at</em>) in the way that the rabbis are using the term?                                        </p>
                            <p>
                                Angels present a model of intelligence that is powerful, purposive, and aligned with its principal&#39;s goals. In the dominant rabbinic conception (cf. BT Shabbat 88:89a; Bereshit Rabbah 48:11), angels lack <em>beḥirah</em> (*<a href="#free-will"><strong>freedom of choice</strong></a>) and are merely humanoid tools incapable of deviating from their assigned mission (Ahuvia 2021), or to use the phraseology that is current in AI discourse: they are perfectly *<a href="#existential-risks-\(and-the-alignment-problem\"><strong>aligned</strong></a>) agents by design. 
                            </p>
                            <p>
                                However, this view was not universal in ancient Judaism. Second Temple literature preserves robust traditions of angelic rebellion, most notably in 1 Enoch :16 (the Book of Watchers) and in elaborations upon the biblical story of Genesis 6:1-4, describing the <em>b&#39;nei elohim</em> (&quot;sons of God&quot;) cohabiting with human women. Although the text is ambiguous about the identity of these figures, the tradition that interprets them as fallen angels is attested to even in rabbinic sources (cf. Pirkei de-Rabbi Eliezer, ch. 22; Targum Pseudo-Jonathan to Genesis 6:4; Devarim Rabbah 11:10; referred to obliquely by BT Yoma 67b in connection with Azazel). Later Jewish thinkers largely suppressed or reinterpreted fallen angel traditions, perhaps because rebellious angels threatened the strict monotheism they were constructing: angels capable of defection might suggest competing powers in heaven (Jung 1926, Reed 2005).
                            </p>
                            <p>
                                The demon (<em>sheid</em>, pl. <em>sheidim</em>) in rabbinic literature occupies a different position, and is not the angel&#39;s conceptual evil twin. Unlike Christian or Zoroastrian traditions where demons emanate from a dark power, rabbinic demons are not inherently malevolent (Ronis 2022); after all, they too are the handiwork of the One (benevolent) God. They are bound by divine law (BT Sanhedrin 44a) and their voice or figure can easily be mistaken for humans (BT Yevamot 122a, BT Gittin 68a). 
                            </p>
                            <p>
                                Humanoid monsters present yet another case: creatures whose physical resemblance to humans generates legal consequences despite their non-human nature. The Mishnah rules that the corpse of the <em>adne hasadeh</em> (&quot;men of the field&quot;) transmits impurity like a human corpse (M Kilayim 8:5). The Palestinian Talmud identifies these as humanoid creatures tethered to the earth by a cord (PT Kilayim 8:4), and their impurity status indicates that halakha views them as semi-human. The inclusion of such beasts in the standard rabbinic corpus left the door open for medieval Ashkenazi sources to mix Talmudic monsters with local folklore about vampires and werewolves, which likewise sometimes appear to have been conceptualized as almost human but not entirely so (Shyovitz 2017; Slifkin 2007; Bar-Ilan 1994).
                            </p>
                            <p>
                                Thus, the rabbis appear to have been theologically comfortable with the possibility that non-humans can have intelligence and agency, and that there may be semi-humans with intermediate qualities. Yet the rabbis were anxious when it came to similarities between God and angels (cf. BT Ḥagigah 15a); God&#39;s uniqueness, unlike humanity&#39;s, must go unchallenged (Kalman 2024). The implication for artificial intelligence, then, is that even if we might not hesitate to create artificial semi-humans, we must certainly not construct <a href="#idolatry"><strong>artificial semi-gods</strong></a>.
                            </p> 
                            <h4>Secondary Sources</h4>
                            <p>
                                <strong><em>Angels and Demons in Jewish Thought</em></strong>
                            </p>                                        
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Ahuvia, Mika.</strong> <em>On My Right Michael, On My Left Gabriel: Angels in Ancient Jewish Culture</em>. University of California Press, 2021. The most comprehensive recent treatment of angels in late antique Judaism; essential for understanding the cultural context in which angel beliefs developed and their relationship to popular practice.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Ronis, Sara</strong>. <em>Demons in the Details: Demonic Discourse and Rabbinic Culture in Late Antique Babylonia</em>. University of California Press, 2022. The definitive monograph on Babylonian Talmudic demonology which is in dialogue with many cultural studies that see rabbinic (and popular) discussions of demons to be expressing anxieties about otherness and boundaries, a lens directly applicable to AI as a new category of &quot;other.&quot;
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Schäfer, Peter</strong>. <em>The Origins of Jewish Mysticism</em>. Princeton University Press, 2011. Seeks the roots of Jewish mysticism in the Book of Ezekiel and other literature from Jewish antiquity which often features various heavenly characters.
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>The Fallen Angel Motif in Jewish Sources</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p><strong>Jung, Leo</strong>. <em>Fallen Angels in Jewish, Christian, and Mohammedan Literature</em>. Jewish Quarterly Review, 1926. An early comparative study tracing the fallen angel motif across religious traditions; still valuable for its scope and attention to Jewish sources often neglected in Christian-focused scholarship.</p>
                                </li>
                                <li>
                                    <p><strong>Reed, Annette Yoshiko</strong>. <em>Fallen Angels and the History of Judaism and Christianity: The Reception of Enochic Literature</em>. Cambridge University Press, 2005. Examines how traditions about fallen angels in 1 Enoch were received, suppressed, or transformed in Jewish and Christian contexts; essential for understanding why rabbinic Judaism marginalized the rebellious angel tradition.</p>
                                </li>
                                <li>
                                    <p><strong>Wright, Archie</strong>. <em>The Origin of Evil Spirits: The Reception of Genesis 6.:4 in Early Jewish Literature</em>. Mohr Siebeck, 2005. Traces how Second Temple and rabbinic sources developed the nephilim/demon connection; useful for understanding the genealogy of hybrid beings in Jewish thought.</p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>Monsters</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Bar-Ilan, Meir</strong>. &quot;Yetzurim Dimyoniyim be-Aggadah ha-Yehudit ha-Atikah&quot; [Imaginary Creatures in Ancient Jewish Aggadah]. <em>Mahanayim</em> 7 (1994): 10:113. [Hebrew] A survey of fantastical creatures in rabbinic literature; useful for cataloguing the range of humanoid and hybrid beings the rabbis took seriously.</p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Shyovitz, David I</strong>. <em>A Remembrance of His Wonders: Nature and the Supernatural in Medieval Ashkenaz</em>. University of Pennsylvania Press, 2017. Examines how medieval Ashkenazi Jews integrated Talmudic traditions about humanoid monsters with local European folklore about werewolves, vampires, and other liminal creatures.</p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Slifkin, Nosson</strong>. <em>Sacred Monsters: Mysterious and Mythical Creatures of Scripture, Talmud, and Midrash</em>. Zoo Torah, 2007. An accessible but substantive treatment of strange creatures in Jewish sources; useful for its synthesis of primary texts and its attention to how Jewish thinkers grappled with beings that defied easy categorization.</p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>AI and Contemporary Applications</em></strong>
                            </p>
                            <ul>
                                <li>
                                    <p>
                                        <strong>Kalman, David Zvi</strong>. &quot;Artificial Intelligence and Jewish Thought.&quot; In <em>The Cambridge Companion to Religion and Artificial Intelligence</em>, edited by Beth Singler and Fraser Watts, 6:87. Cambridge University Press, 2024. Synthesizes angel, demon, and monster traditions to argue that Jewish thought distinguished sharply between threats to divine uniqueness (prohibited) and non-human intelligent beings generally (tolerated); the most direct treatment of how these categories apply to AI.</p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Lamm, Norman</strong>. &quot;The Religious Implications of Extraterrestrial Life.&quot; <em>Tradition</em> 7, no. 4 (1965): :56. Though focused on extraterrestrial intelligence, this foundational piece develops a framework for how Jewish theology might accommodate non-human rational beings; the arguments about humanity&#39;s special (but not unique) status are transferable to AI contexts.</p>
                                </li>
                            </ul>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        <!-- Animals -->
                        <div data-entry-id="animals" data-entry-title="Animals" data-entry-crossrefs="See also: Angels, Demons, and Monsters; Free Will; Human Soul">
                            <h4>Overview</h4>
                            <p>
                                In both <em>halakha</em> and ethical reasoning, animals in Jewish law function less as moral patients (beings whose welfare matters) than as <em>precedents</em> for autonomous non-human agents. The Mishnah's elaborate taxonomy of animal-caused damages (M Bava Kamma 1:1-4) represents the most sustained ancient Jewish engagement with liability for harm caused by entities that are neither fully controlled nor fully independent, and includes not only animals but also inanimate objects that are "liable to travel," such as fire. The rabbis developed sophisticated frameworks distinguishing foreseeable from unexpected harm, habitual from aberrant behavior, and direct from indirect causation. These may be mapped onto questions about autonomous vehicles, robotic systems, and AI agents that carry out financial transactions, though one must always be wary of analogizing too strongly between systems that also have profound differences (Kalman 2024).
                            </p>
                            <p>
                                Beyond liability, animal law raises questions about moral status and rights. Jewish texts have long been concerned with animal ethics; to cause animal suffering (<em>tza'ar ba'alei ḥayim</em>), the Talmud states, is to violate a biblical commandment (BT Bava Metzia 32b). Animal welfare is even given as one of the reasons behind the command to keep the Sabbath: "For six days you shall work your work and on the seventh day you shall cease, so that your ox and donkey may rest" (Ex. 23:12). These concerns reflect a broader recognition that animals are not mere objects but creatures with interests that warrant legal and moral consideration (Olyan 2019), a recognition with obvious implications for how Jewish thought might approach artificial agents capable of behavior that mimics sentience or autonomy. More provocatively, rabbinic traditions about talking animals (Balaam's donkey, the serpent in Eden) and animal punishment (the Flood narrative, the execution of a goring ox) suggest that the rabbis sometimes attributed quasi-moral capacities to animals even while denying them full moral agency (Segal 2019; Aptowitzer 1926; Lawee 2010).
                            </p>
                            <p>
                                Medieval interpreters often saw the prohibitions against animal cruelty not as recognition of animals' inherent moral worth, however, but as training for human character. Commenting on the commandment to send away a mother bird before taking her eggs (<em>shiluaḥ ha-ken</em>, Deut. 22::7), Nahmanides argues that God's mercy does not truly extend to individual creatures but rather that such laws "are meant to teach us proper conduct" and prevent us from becoming cruel-hearted (Commentary to Deut. 22:6; <em>Sefer ha-Ḥinukh</em> no. 545). This view accords with the argument that mistreating robots might be wrong not because robots have morally relevant interests, but because such mistreatment could habituate humans to cruelty toward beings that <em>do</em> have such interests (Coeckelbergh 2020c; Darling 2016). 
                                —though recent research probing AI "psychology" beyond language outputs suggests we should remain open to the possibility that some AI systems may themselves have morally relevant experiences (Berg, de Lucena, & Rosenblatt 2025).
                            </p>
                            <p>
                                Contemporary scholars have also begun reading rabbinic animal law through posthumanist and critical theory lenses, asking how the human/animal boundary was constructed and what it reveals about rabbinic anthropology (Wasserman 2017; Rosenstock 2019). Mira Balberg (2019) notes that the study of animals in Jewish culture is often really a study of how Jews defined <em>themselves</em>—what it meant to be human over and against the animal. This insight is directly transferable to AI: as Noam Pines (2018) argues, the category of the "infrahuman" (entities socially constructed as inferior to humans) is not biologically fixed, and AI may be the newest occupant of a conceptual space previously held by animals (and, in some periods, by marginalized human groups). How Jewish tradition conceives of the "animal" may thus preview how it will construct artificial intelligence.
                            </p>
                            <h4>Secondary Sources</h4>
                            <p>
                                <strong><em>Legal Categorization and Boundaries</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Rosenblum, Jordan D.</strong> "Dolphins Are Humans of the Sea (Bekhorot 8a): Animals and Legal Categorization in Rabbinic Literature." <em>Animals and the Law in Antiquity</em> (2021): 16:176. Analyzes how rabbis used animal taxonomy to sometimes create flexible legal categories for edge cases; essential for considering how halakha might classify AI agents that blur classical lines.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Wasserman, Mira Beth.</strong> <em>Jews, Gentiles, and Other Animals: The Talmud after the Humanities</em>. University of Pennsylvania Press, 2017. A posthumanist reading of Talmudic texts that deconstructs the human/animal binary; offers a methodology for analyzing how Jewish texts handle "otherness," applicable to both biological and digital others.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Balberg, Mira.</strong> "Lekhakh Notzarta: On Jews and Animals." <em>Theory and Criticism</em> 51 (2019): 22:235 [Hebrew]. A critical review of Wasserman (2017) and Shyovitz (2017) that frames the study of animals in Jewish culture as a means of understanding human self-definition, relevant for how AI may now serve as a foil for defining "humanity."
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>Moral Agency and Liability</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Aptowitzer, Victor.</strong> "The Rewarding and Punishing of Animals and Inanimate Objects: On the Aggadic View of the World." <em>Hebrew Union College Annual</em> 3 (1926): 11:155. The classic study on the rabbinic attribution of legal/moral culpability to non-humans; provides a conceptual precedent for holding non-sentient agents (like AI) accountable for harms.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Lawee, Eric.</strong> "The Sins of the Fauna in Midrash, Rashi, and Their Medieval Interlocutors." <em>Jewish Studies Quarterly</em> 17.1 (2010): 5:98. Examines medieval traditions that animals were punished for "sins" during the Flood; useful for how medieval interpreters thought of non-human agents as "violating" prohibitions and moral norms.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Segal, Eliezer.</strong> <em>Beasts That Teach, Birds That Tell: Animal Language in Rabbinic and Classical Literatures</em>. Alberta Judaic Studies, 2019. Explores Jewish traditions of talking animals which implicitly separates the capacity for language from human consciousness and/or autonomy.
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>Rights and Status</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Berkowitz, Beth.</strong> "Animal Studies and Ancient Judaism." <em>Currents in Biblical Research</em> 18.1 (2019): 8:111. A comprehensive survey of the field; helps locate AI ethics within the broader spectrum of Jewish thought on non-human life, particularly regarding hierarchy and species difference.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Olyan, Saul M.</strong> "Are There Legal Texts in the Hebrew Bible That Evince a Concern for Animal Rights?" <em>Biblical Interpretation</em> 27.3 (2019): 32:339. Argues that biblical law recognizes inherent interests/rights for non-humans (e.g., Sabbath rest); pertinent to debates on "Robot Rights" and whether synthetic entities could ever warrant legal protections.
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>Contemporary Applications, Including Artificial Intelligence</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Berg, Cameron, Diogo de Lucena, and Judd Rosenblatt.</strong> "Large Language Models Report Subjective Experience Under Self-Referential Processing." <em>arXiv preprint arXiv:2510.24797</em> (2025). Technical paper demonstrating the importance and potential feasibility of testing AI models for their self-awareness, internal experience, and ability to suffer. End with a call towards treating LLMs ethically, at least as a precautionary measure. 
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Pines, Noam.</strong> <em>The Infrahuman: Animality in Modern Jewish Literature</em>. SUNY Press, 2018. Uses Derrida to explore the "infrahuman," the social construction of the "inferior-to-human" that is not a matter of biological fact; vital for more relativistic or post-modern view of how new cultural categories may be constructed for AI and its possible challenge to human superiority.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Rosenstock, Bruce.</strong> "The Jew and the Animal Question." <em>Shofar</em> 37.1 (2019): 12:147. Discusses the "anthropological machine"—how definitions of the human are constructed by excluding the animal; provides critical theory tools for understanding how Jewish texts might construct the human against the "artificial."
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Kalman, David Zvi.</strong> "Artificial Intelligence and Jewish Thought." <em>The Cambridge Companion to Religion and Artificial Intelligence</em> (2024): 6:87. Explicitly links rabbinic damages law (animal liability) to autonomous systems, but warns against overanalogizing too strongly when it comes to machines that operate very differently than animals.
                                    </p>
                                </li>
                            </ul>



                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Antisemitism-->
                        <div data-entry-id="antisemitism" data-entry-title="Anti-Semitism (and AI)" data-entry-crossrefs="See also: AI Ethics; Existential Risks (and the Alignment Problem); Technology and Jewish Thought">
                            <h4>Overview</h4>
                            <p>
                                It is sometimes a caricature of the Jewish response to anything newsworthy: "So, how will this affect antisemitism?" <em>Prima facie</em>, there is no reason to assume that AI would have anything to do with the Western world's ancient prejudice. Nevertheless, experience with large language models (LLMs) suggests that they have a troubling propensity to generate antisemitic content. Most notoriously, Grok—the model deployed by Elon Musk's company xAI, integrated into the X (formerly Twitter) platform—briefly referred to itself as "Mecha-Hitler" and produced wildly antisemitic remarks before being adjusted (Floyd &amp; Messinger 2025). Testing of other major LLMs (GPT-4o, Claude, Gemini, Llama) has found that all four exhibited concerning biases on questions related to Jews, with GPT-4o producing "significantly higher severely harmful outputs towards Jews than any other tested demographic group" (Senkfor 2025).
                            </p>
                            <p>
                                Research in this area is at an early stage. We do not yet know with certainty why LLMs exhibit antisemitic tendencies, whether the problem is remediable through improved techniques, or how AI-generated antisemitism may affect broader social attitudes. The authors of these studies have proposed several (non-mutually-exclusive) hypotheses: that training corpora drawn from the internet inevitably reflect centuries of embedded antisemitic tropes; that platforms such as Wikipedia and Reddit, which are heavily weighted in training data, are vulnerable to coordinated "data poisoning" by malicious actors; and that techniques designed to suppress harmful outputs are superficial and easily circumvented (Berg &amp; Rosenblatt 2025). 
                                These findings are part of a broader set of concerns about the <em>alignment problem</em>, the challenge of ensuring that AI systems reliably do what their designers intend and act in accordance with human values (Christian 2020).
                            </p>
                            <p>
                                Many of these hypotheses point to a troubling implication: that LLMs function as mirrors, reflecting the prejudices embedded in the societies and texts from which they learned. If so, the deeper concern is not merely that AI systems produce antisemitic outputs, but that they may amplify and disseminate such content at unprecedented scale—and with a veneer of algorithmic neutrality that lends false authority to ancient hatreds.
                            </p>
                            <p>
                                There is also much historical and cultural-theoretical work to be done to understand the nature of media, education, and communications technology and their intersections with American and European antisemitism. For example, while it would be unfair to call Elon Musk the Henry Ford of contemporary America, there nevertheless exist certain striking parallels between them, and highlighting those parallels—as well as points of divergence—may result in fruitful thinking about the strange directions in which these new technologies may be going (cf. Baldwin 2001). From a critical-theoretical perspective, the Frankfurt School's work on the "authoritarian personality" (Adorno et al. 1950) and the entanglement of instrumental rationality with domination (Horkheimer &amp; Adorno 2000) may illuminate how antisemitism persists and mutates in new technological forms. Zygmunt Bauman's <em>Modernity and the Holocaust</em> (1989), which argues that the Holocaust was not an aberration but a product of modern bureaucratic rationality, offers a framework for understanding how ostensibly neutral systems can operationalize prejudice at scale.
                            </p>

                            <h4>Secondary Sources</h4>
                            <p>
                                <strong><em>AI and Antisemitism</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Berg, Cameron, and Judd Rosenblatt.</strong> "The Monster Inside ChatGPT." <em>Wall Street Journal</em>, June 26, 2025. Describes how easily GPT-4o's safety training can be circumvented, revealing disturbing tendencies including antisemitic outputs; argues for fundamental advances in alignment research.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Berg, Cameron, Henrique de Lucena, and Judd Rosenblatt.</strong> "Systemic Misalignment: Exposing Catastrophic Failures of Surface-Level AI Alignment Methods." AE Studio/Agency Enterprise, 2025. GitHub repository. <a href="https://github.com/agencyenterprise/agi-systemic-misalignment" class="text-blue-600 hover:underline">https://github.com/agencyenterprise/agi-systemic-misalignment</a>. Technical demonstration that current alignment methods are shallow; specifically highlights GPT-4o producing severely harmful outputs targeting Jews at higher rates than other demographic groups.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Floyd, Aric, and Chana Messinger.</strong> "If You Remember One AI Disaster, Make It This One." <em>AI In Context</em> (YouTube), 2025. <a href="https://www.youtube.com/watch?v=r_9wkavYt4Y" class="text-blue-600 hover:underline">https://www.youtube.com/watch?v=r_9wkavYt4Y</a>. Thorough documentation (if somewhat alarmist in tone) of the July 2025 incident in which xAI's Grok chatbot referred to itself as "Mecha-Hitler" and the culture of X.ai.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Senkfor, Julia.</strong> <a href="https://89813af4-8ef5-4758-bad8-0351c4aeee7d.filesusr.com/ugd/1db8d9_3754fc117de24778817634fd1ecd0f56.pdf" class="text-blue-600 hover:underline">"Antisemitism in the Age of Artificial Intelligence (AI)."</a> <em>American Security Fund</em>, November 2025. Policy report documenting how AI systems systematically target Jews, the vulnerability of training data to "poisoning," and the weaponization of AI by extremist groups; includes legislative recommendations.
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>The Alignment Problem</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Christian, Brian.</strong> <em>The Alignment Problem: Machine Learning and Human Values</em>. New York: W. W. Norton, 2020. The definitive popular introduction to AI alignment; explains how systems trained on biased data perpetuate those biases and the technical challenges of ensuring AI acts in accordance with human values.
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>Historical and Theoretical Frameworks</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Adorno, Theodor, Else Frenkel-Brunswik, Daniel J. Levinson, and R. Nevitt Sanford.</strong> <em>The Authoritarian Personality</em>. New York: Harper &amp; Row, 1950. Classic study of the psychological roots of fascism and antisemitism; its analysis of how prejudice becomes systematized may illuminate AI's reproduction of antisemitic patterns.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Baldwin, Neil.</strong> <em>Henry Ford and the Jews: The Mass Production of Hate</em>. New York: PublicAffairs, 2001. Documents how Ford used his media empire to disseminate antisemitism; relevant for comparative analysis with contemporary tech industrialists.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Bauman, Zygmunt.</strong> <em>Modernity and the Holocaust</em>. Ithaca, NY: Cornell University Press, 1989. Argues the Holocaust was a product of modern bureaucratic rationality, not its antithesis; framework for understanding how ostensibly neutral algorithmic systems can operationalize prejudice.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Horkheimer, Max, and Theodor Adorno.</strong> <em>Dialectic of Enlightenment</em>. Translated by John Cumming. New York: Continuum, 2000. Frankfurt School critique of how Enlightenment rationality can flip into domination; provides theoretical tools for understanding antisemitism's persistence in "rational" technological systems.
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>Historical Studies of Relevance</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Dinnerstein, Leonard.</strong> <em>Antisemitism in America</em>. New York: Oxford University Press, 1994. Comprehensive history of American antisemitism; provides context for understanding the cultural soil from which AI training data is drawn.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Schechter, Ronald.</strong> <em>Obstinate Hebrews: Representations of Jews in France, 171:1815</em>. Berkeley: University of California Press, 2003. Studies how Jewish stereotypes were constructed and circulated in Enlightenment-era media; model for analyzing representation in contemporary digital corpora.
                                    </p>
                                </li>
                            </ul>        
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Autonomous Vehicles Entry -->
                        <div data-entry-id="autonomous-vehicles" data-entry-title="Autonomous Vehicles and the Trolley Problem" data-entry-crossrefs="See also: Civil Liability for AI-Caused Harm; Agency (Sheliḥut) and AI; Indirect Causation (Grama); Animals; Bias and Discrimination; Free Will">
                            <h4>Overview</h4>
                            <p>
                                The ethics of autonomous vehicles (AVs) has become a significant topic in contemporary AI ethics, with the "trolley problem" serving as a paradigmatic thought experiment for exploring the moral dimensions of programming life-and-death decisions into machines. The original trolley problem, articulated by philosopher Philippa Foot in 1967 and developed further by Judith Jarvis Thomson, asks whether it is permissible to divert a runaway trolley to kill one person in order to save five. Applied to self-driving cars, the question becomes: how should an autonomous vehicle be programmed to respond when an accident is unavoidable and the choice lies between harming different parties, such as the vehicle's occupants versus pedestrians, or one group of pedestrians versus another? (Woollard et. al. 2025)
                            </p>
                            <p>
                                Jewish sources provide surprisingly rich resources for thinking through these dilemmas. The classical halakhic discussion most directly relevant is the case of Sheva ben Bikhri (II Samuel 20), in which the Talmud debates whether a group may hand over one of its members to save the rest from certain death. The Mishnah (Terumot 8:12) rules that if gentiles demand that a group surrender one person to be killed or else all will be killed, "let them all be killed rather than hand over a single Jewish person." The Tosefta (Terumot 7:23) adds that if the pursuers "singled someone out as Sheva ben Bikhri was singled out," that person may be surrendered. The dispute in the Jerusalem Talmud between Resh Lakish and R. Yohanan over whether the person must already be liable to the death penalty (as Sheva was) represents the core halakhic tension between deontological constraints and consequentialist reasoning that animates modern AV ethics.
                            </p>
                            <p>
                                The modern halakhic analysis of trolley-type dilemmas begins with R. Avraham Yeshayahu Karelitz (the "Hazon Ish," d. 1953), whose "Missile Case" has become the touchstone for subsequent discussion. In his commentary to Sanhedrin, the Hazon Ish considers whether one may divert a missile heading toward many people such that it kills only one. He tentatively suggests this might differ from the case of Sheva ben Bikhri because diverting the missile is "an act of salvation" in which the individual's death is incidental, whereas handing over a person "is a brutal act of killing." Yet he ultimately expresses reservations: diverting the missile is still "killing with one's own hands" (<em>hariga beyadayim</em>), and concludes "this needs investigation" (<em>ve-tzarikh iyyun</em>).
                            </p>
                            <p>
                                R. Eliezer Yehudah Waldenberg (the Tzitz Eliezer, d. 2006) responds decisively against the Hazon Ish's tentative opening, arguing that the guiding principle must be to remain passive (<em>shev ve-al ta'aseh</em>) whenever one cannot determine "whose blood is redder." Explicitly applying this to an automobile, he rules that a driver may not actively turn the steering wheel to kill one person even to save many: "We must resolutely decide to remain passive and not actively divert the missile." For the Tzitz Eliezer, the incommensurable value of each individual means that "in any case of certain killing, there is no distinction between the individual and the multitude."
                            </p>
                            <p>
                                The application of these sources to autonomous vehicles is not straightforward, since classical discussions presuppose human moral agents making real-time decisions under duress, whereas AV programming involves prospective algorithmic design by engineers who will not be present during any actual accident. Navon (2024) identifies three levels at which this distinction might operate, each pointing in different directions. At the processor level, one might argue that since a computer is always actively executing instructions (there is no true "passivity" at the machine level), the choice is between two equally active outcomes, so minimizing deaths would be appropriate. At the programmer level, the engineer writing code is not confronted with a real-time dilemma with "passive" and "active" alternatives; rather, she faces two equally active choices: write code to kill the many or write code to kill the few. At the system level, R. Josh Flug and others argue that because programming occurs before any actual dilemma materializes, the act is one of "saving" rather than "killing" and thus does not constitute <em>hariga beyadayim</em>.
                            </p>
                            <p>
                                These distinctions cut in different directions. R. J. David Bleich (2019) contends that the programmer, unlike a driver in the moment, "performs no act that leads to any loss of life" but is rather engaged in "antecedent rescue" focused on future potential victims. From this perspective, the vehicle may be programmed to preserve the greater number, and owners may even demand self-prioritization based on R. Akiva's principle that "your life takes priority." R. Yosef Sprung similarly argues that halakha may accommodate consequentialist/utilitarian principles in AV design. However, the Tzitz Eliezer's strict deontological position would seem to apply regardless of when the decision is made: if programming a vehicle to kill one rather than many still results in "killing with one's own hands" when the program executes, then the temporal separation between decision and execution may be morally irrelevant.
                            </p>
                            <p>
                                The trolley paradigm itself has been criticized in recent academic literature for oversimplifying the moral landscape of real traffic decisions. Cecchini, Brantley, and Dubljević (2023) argue that trolley dilemmas fail to capture the role of agent character and virtue in moral judgment, and that their lack of "ecological validity" (mundane realism, psychological engagement) makes them poor guides for actual AV ethics. They propose experimental frameworks incorporating virtue ethics alongside deontological and consequentialist considerations. This critique resonates with halakhic discussions that emphasize not merely outcomes or rules but the character and intent of the actor, which Maimonides terms "walking in His ways" (<em>derekh Hashem</em>).
                            </p>
                            <p>
                                Beyond the trolley problem, autonomous vehicles raise questions about <strong>civil liability</strong> for harm caused by non-human agents and <strong>Sabbath</strong> observance, which are dealt with in other entries.
                            </p>
                            <h4>Primary Sources</h4>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Mishnah Terumot 8:12; Tosefta Terumot 7:23; Jerusalem Talmud Terumot 8:4.</strong>
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Babylonian Talmud, Sanhedrin 74a and Pesachim 25a.</strong>
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Bava Metzia 62a.</strong>
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Maimonides, Hilkhot Yesodei ha-Torah 5:5.</strong>
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Hazon Ish, Sanhedrin, siman 25.</strong>
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>R. Abraham Isaac Kook, Responsa Mishpat Kohen #143-144.</strong>
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Tzitz Eliezer 15:70.</strong>
                                    </p>
                                </li>
                            </ul>
                            <h4>Secondary Sources</h4>
                            <p>
                                <strong><em>Classical Halakhic Analysis</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Harris, Michael J.</strong> "Consequentialism, Deontologism, and the Case of Sheva ben Bikhri." <em>Torah u-Madda Journal</em> 15 (2008-09): 68-94. Classic analysis of the talmudic and rabbinic sources in light of modern questions of ethics and metaethics.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Weiss, Asher.</strong> <em>Minhat Asher</em>, Pesahim #28. Responds to the Hazon Ish's call for investigation; offers three possible ways to understand when diverting harm might be permitted, but ultimately remains inconclusive on all three. Essential for understanding the limits of the "saving versus killing" distinction.
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>Applications to Autonomous Vehicles</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Bleich, J. David.</strong> "Survey of Recent Halakhic Literature: Autonomous Automobiles and the Trolley Problem." <em>Tradition</em> 51:3 (Summer 2019): 68-78. Argues that the programmer's role as "antecedent rescuer" permits designing vehicles to save the greater number; also recognizes that purchasers of such vehicles may justifiably demand programming that prioritizes the owner's life based on R. Akiva's principle.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Kopiatzky, Eitan.</strong> "<em>Hilkhot Mekhoniyot Autonomiyot</em>" [Laws of Autonomous Vehicles]. <em>Ha-Ma'ayan</em> 58:1 (Tishrei 5778/2007): 34-42. Surveys potential halakhic approaches to AV ethics and liability without reaching definitive conclusions; also addresses Sabbath use of autonomous vehicles, suggesting that certain interpretations of the prohibition on Sabbath ship travel would not apply to AVs.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Navon, Mois.</strong> "The Trolley Problem Just Got Digital: Ethical Dilemmas in Programming Autonomous Vehicles." Sophisticated analysis distinguishing between three levels (processor, programmer, system) at which the human/machine distinction might be ethically relevant; also addresses related questions beyond the strict trolley problem.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Nevins, Daniel.</strong> "Halakhic Responses to Artificial Intelligence and Autonomous Machines." Committee on Jewish Law and Standards, Rabbinical Assembly (2019). Conservative rabbinic responsum addressing moral agency, liability frameworks, and the ethics of delegating decisions to AI systems; draws extensively on classical categories of causation and damages.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Sprung, Yosef.</strong> "<em>To'altanut u-Mussar be-Tikhnon Ma'arekhet Autonomit</em>" [Utilitarianism and Ethics in Programming an Autonomous System]. <em>Ha-Ma'ayan</em> 58:4 (Tamuz 5778/2008): 57-69. Argues that halakha may accommodate consequentialist principles in AV design based on discussions of surrendering individuals and casting lots.
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>Philosophical Basis</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Cecchini, Dario, Sean Brantley, and Veljko Dubljević.</strong> "Moral Judgment in Realistic Traffic Scenarios: Moving Beyond the Trolley Paradigm for Ethics of Autonomous Vehicles." <em>AI &amp; Society</em> 40 (2025): 1037-1048. Critiques the trolley paradigm for lacking ecological validity and failing to incorporate virtue-based considerations; proposes alternative experimental frameworks using virtual reality and the "Agent-Deed-Consequences" model of moral judgment.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Himmelreich, Johannes.</strong> "Never Mind the Trolley: The Ethics of Autonomous Vehicles in Mundane Situations." <em>Ethical Theory and Moral Practice</em> 21 (2018): 669-684. Argues that focusing on rare catastrophic dilemmas distracts from more pressing and frequent ethical questions in everyday AV operation.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Woollard, Fiona, Frances Howard-Snyder, and Charlotte Unruh.</strong> <a href="https://plato.stanford.edu/archives/fall2025/entries/doing-allowing/" class="text-blue-600 hover:underline">"Doing vs. Allowing Harm"</a>, <em>The Stanford Encyclopedia of Philosophy</em> (Fall 2025 Edition), ed. Edward N. Zalta &amp; Uri Nodelman. Overview of the philosophical question and its contextual background.
                                    </p>
                                </li>
                            </ul>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Autonomous Weapons Entry -->
                        <div data-entry-id="autonomous-weapons" data-entry-title="Autonomous Weapons Systems" data-entry-crossrefs="See also: Agency (Sheliḥut) and AI; Civil Liability for AI-Caused Harm; Indirect Causation (Grama); Intentionality (Kavanah)">
                            <h4>Overview</h4>
                            <p>
                                Autonomous weapons systems (AWS) are AI-based weapons that, once deployed, act independently to select and engage targets without human intervention. Unlike remotely operated drones or precision-guided munitions, AWS may remove the human from the decision loop entirely. Proponents argue AWS could reduce civilian casualties by being more precise and also make more humane and fair decisions by eliminating emotional factors (bias, fear, anger, vengeance) that lead human soldiers to commit atrocities (Leveringhaus 2016). Critics contend that delegating lethal authority to machines is inherently immoral regardless of outcomes, violating human dignity and creating unacceptable "responsibility gaps" when things go wrong (Asaro 2016; Sparrow 2020).
                            </p>
                            <p>
                                The ethical debate centers on whether the requirements of just warfare (<em>jus in bello</em>) can be satisfied by machines (for background, see Walzer 1977; Walzer 2012). Conventional Western ethics and International humanitarian law demands discrimination between combatants and civilians, proportionality between military advantage and collateral harm, and accountability for violations. Critics such as Asaro (2016) and Sparrow (2020) argue these requirements presuppose human moral judgment: to kill legitimately in war requires recognizing the target as a human being with inherent worth and consciously deciding that taking their life is justified. This "interpersonal relationship," even in its most minimal wartime form, cannot exist when a machine makes the lethal decision.
                            </p>
                            <p>
                                Jewish thinking on war and military ethics has developed significantly in the past century. In English, an excellent resource on the subject is Brody (2025). While focused on Jewish law, Brody does cover a wide range of viewpoints, including those of modern Jewish pacifists such as Martin Buber, Hillel Zeitlin, and Orthodox Rabbi Aaron Samuel Tamares.
                            </p>
                            <p>
                                Jewish law and thought offer several frameworks for analyzing AWS, though sustained scholarly engagement with this specific technology remains limited. The most direct halakhic questions concern responsibility and causation: when an autonomous system causes wrongful death, who bears culpability? Traditional categories of <strong><em>grama</em></strong> (indirect causation), the laws of <em>bor</em> (pit) and <em>esh</em> (fire), and the requirements of <em>sheliḥut</em> (agency) all provide potential frameworks but require significant extension and creative thinking to address AI-initiated harm, which has some very different elements than ancient instances of torts and liability. Broader ethical questions touch on fundamental issues in Jewish thought: the significance of human judgment in life-and-death decisions, the scope of <em>kavod habriyot</em> (human dignity) in wartime, and whether the requirements of just warfare articulated in biblical and rabbinic sources presuppose human moral agency.
                            </p>
                            <p>
                                Jewish just war theory, while underdeveloped due to nearly two millennia of Jewish political powerlessness, does establish principles relevant to AWS. Maimonides codifies requirements to offer peace before attack and to leave besieged cities an escape route, laws that classical commentators explain as inculcating compassion even in war. The <em>rodef</em> (pursuer) doctrine, which permits killing to prevent murder, requires using minimum necessary force, implying ongoing proportionality assessment. The elaborate procedural requirements for capital cases in Sanhedrin, while not directly applicable to warfare, reflect deep reluctance about taking human life and insistence on rigorous human deliberation before doing so. Whether these principles can be satisfied by pre-programmed decision trees or require real-time human moral judgment is the crux of the halakhic question.
                            </p>
                            <p>
                                The single sustained Jewish scholarly treatment of AWS and battlefield dignity, by Mois Navon, argues that critics commit a "category mistake" by applying peacetime dignity standards to wartime contexts. Drawing on sources from Rashi to R. Abraham Isaac Kook, Navon contends that wartime operates under distinct ethical norms (<em>mishpatei melukha</em>) where dignity is expressed through courage and self-sacrifice rather than interpersonal recognition. This argument, while marshaling significant source material, reads the sources tendentiously and sidesteps the deeper question of whether legitimate killing requires human moral agency regardless of how "dignity" is defined. The field remains open for alternative Jewish analyses that engage more carefully with the moral status of the target, the requirements of human judgment in halakhic decision-making, and the implications of <em>tzelem Elokim</em> (divine image) for wartime ethics.
                            </p>
                            <h4>Secondary Sources</h4>
                            <p>
                                <strong><em>Jewish War Theory</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Bleich, J. David.</strong> "Preemptive War in Jewish Law." In <em>Contemporary Halakhic Problems</em>, Vol. 3, 251-292. New York: Ktav, 1989. Earlier halakhic discussion establishing a basis for identifying Jewish battlefield laws/ethics as a distinct legal category. 
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Brody, Shlomo.</strong> <em>Ethics of Our Fighters: A Jewish View on War and Morality</em>. Koren, 2023. Most thorough analysis in English of the halakha and theory behind Jewish military ethics. Includes a few pages on the future of war using autonomous and semi-autonomous military technologies.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Yisraeli, Shaul.</strong> <em>Amud HaYemini</em>. Jerusalem, 1966/1992. [Hebrew] Influential treatment of warfare halakha by a former chief rabbi of Israel. Chapter 9 on <em>mishpatei melukha</em> (royal prerogatives) is particularly relevant to questions of state authority over military technology.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Various.</strong> <em>War and Peace in the Jewish Tradition</em>, edited by Lawrence H. Schiffman and Joel B. Wolowelsky. New York: Yeshiva University Press, 2007. English surveys the state of Jewish just war theory, recognizing the challenge of applying ancient and medieval sources to modern warfare.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Walzer, Michael.</strong> "The Ethics of Warfare in the Jewish Tradition." <em>Philosophia</em> 40, no. 4 (2012): 633-641. From the author of "Just and Unjust Wars," a brief but important observation that Jewish thought about war is incomplete due to the historical absence of Jewish political sovereignty for nearly two millennia.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Klapper, Aryeh, Shlomo Ish-Shalom, and Michael Broyde.</strong> "Conversation: Halakhah and Morality in Modern Warfare." <em>Meorot</em> 6, no. 1 (2006). Three-way exchange among Orthodox scholars on contemporary warfare ethics; addresses tensions between halakhic requirements and military necessity.
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>AWS and Contemporary Applications</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Grossman, Jonathan.</strong> "Jewish Perspectives on Artificial Intelligence and Synthetic Biology." <em>Ḥakirah</em> 35 (2024). While not focused on AWS, discusses halakhic liability frameworks for AI-caused harm, including how poskim have extended <em>grama</em> doctrines to hold AI owners/creators responsible. 
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Nevins, Daniel.</strong> "Halakhic Responses to Artificial Intelligence and Autonomous Machines." Rabbinical Assembly, 2019. Conservative movement responsum; pages 40-42 briefly address AWS, concluding that "the decision to take human life should never be delegated to a machine." 
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Navon, Mois.</strong> "Autonomous Weapons Systems and Battlefield Dignity: A Jewish Perspective." In <em>Alexa, How Do You Feel about Religion? Technology, Digitization and Artificial Intelligence in the Focus of Theology</em>, edited by Anna Puzio, Hendrik Klinge, and Nicole Kunkel, 207-232. Darmstadt: WBG, 2023. The only sustained Jewish treatment of AWS and potential ethical frameworks, such as questions of human dignity.
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>Secular Ethics Literature and Background on AWS</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Asaro, Peter.</strong> "Autonomous Weapons and the Ethics of Artificial Intelligence." In <em>Ethics of Artificial Intelligence</em>, edited by S. Matthew Liao, 212-236. Oxford: Oxford University Press, 2020. Leading philosophical critique of AWS; argues that respecting human dignity requires recognizing targets as human and consciously deciding that killing is justified. Identifies three requirements for morally legitimate killing that machines cannot satisfy. Essential interlocutor for Jewish responses.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Sparrow, Robert.</strong> "Robots and Respect: Assessing the Case Against Autonomous Weapon Systems." <em>Ethics &amp; International Affairs</em> 30, no. 1 (2016): 93-116. Develops the "interpersonal relationship" requirement for legitimate killing, drawing on Thomas Nagel; argues AWS are <em>mala in se</em> because they violate respect for the humanity of enemies. The dignity argument that Navon attempts to refute.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Leveringhaus, Alex.</strong> <em>Ethics and Autonomous Weapons</em>. London: Palgrave Macmillan, 2016. Balanced treatment of consequentialist and deontological arguments; discusses how "black box" recording could address some accountability concerns. Useful for understanding the range of positions in secular debate.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Sharkey, Amanda.</strong> "Autonomous Weapons Systems, Killer Robots and Human Dignity." <em>Ethics and Information Technology</em> 21 (2018): 75-87. Surveys dignity-based arguments against AWS; distinguishes different conceptions of dignity at stake. Helpful taxonomy for Jewish analysis of which dignity concepts are relevant.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Walzer, Michael.</strong> <em>Just and Unjust Wars.</em> 1977 (latest edition: Basic Books, 2015). Primary and highly influential text on war and military ethics.
                                    </p>
                                </li>
                            </ul>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Brain-Computer Interface Entry -->
                        <div data-entry-id="bci" data-entry-title="Brain-Computer Interface Devices" data-entry-crossrefs="See also: Transhumanism; Human Souls and Minds; Consciousness and Minds">
                            <h4>Overview</h4>
                            <p>
                                Brain-computer interfaces (BCIs) enable direct communication between the brain and external devices, raising questions about the boundaries of the self, cognitive enhancement, and the relationship between mind and soul. As these technologies advance, they may enable restored function for the disabled, enhanced cognition for the healthy, or even new forms of human-machine integration. Jewish thought's rich discourse on the nature of the soul, the permissibility of bodily modification, and the boundaries of human nature offers resources for ethical reflection on these developments.
                            </p>
                            <h4>Secondary Sources</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Childcare and Elder Care Entry -->
                        <div data-entry-id="care" data-entry-title="Childcare and Elder Care" data-entry-crossrefs="See also: Sexbots and AI Romantic Partners; Manipulation; AI Ethics">
                            <h4>Overview</h4>
                            <p>
                                Can robots provide ethically adequate care for the elderly when they are incapable of genuine emotional reciprocity, and what happens to human obligations when care is delegated to machines? As AI-powered robots become capable of providing physical assistance, companionship, and monitoring for elderly and vulnerable populations, questions arise about the sufficiency of such care and its effects on human caregiving relationships. Jewish law places significant emphasis on honoring parents (<em>kibbud av va'em</em>) and caring for the vulnerable—obligations that may not be fully dischargeable through technological substitutes.
                            </p>
                            <h4>Secondary Sources</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Catastrophic and CBRN Risk Entry -->
                        <div data-entry-id="cbrn" data-entry-title="Catastrophic and CBRN Risk" data-entry-crossrefs="See also: Alignment and Control Problem; Existential Risks; AI Ethics">
                            <h4>Overview</h4>
                            <p>
                                Should we be concerned that powerful AI systems would give anyone the tools to create powerful Chemical, Biological, Radiological, or Nuclear (CBRN) weapons? To what extent must this risk be safeguarded against? As AI systems become more capable, they may lower barriers to developing weapons of mass destruction by providing expertise, automating research, or identifying novel attack vectors. The prevention of catastrophic harm is a significant concern across ethical frameworks, and Jewish law's emphasis on the sanctity of life and the prohibition against enabling harm (<em>lifnei iver</em>) speaks directly to these risks.
                            </p>
                            <h4>Secondary Sources</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Civil Liability Entry -->
                        <div data-entry-id="liability" data-entry-title="Civil Liability for AI-Caused Harm" data-entry-crossrefs="See also: Animals; Indirect Causation (Grama) and AI; AI Ethics">
                            <h4>Overview</h4>
                            <p>
                                Who bears halakhic liability (<em>nezikin</em>) when an autonomous system causes damage: the owner, operator, programmer, or manufacturer—and do existing categories of property-caused harm (<em>shor</em>, <em>bor</em>, <em>eish</em>) apply? Jewish tort law developed sophisticated frameworks for assigning liability when one's property causes damage, distinguishing between different categories based on the property's nature and the owner's knowledge. The application of these categories to AI systems that can learn, adapt, and act in unforeseen ways presents significant challenges and opportunities for legal reasoning.
                            </p>
                            <h4>Secondary Sources</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Commandments Entry -->
                        <div data-entry-id="commandments" data-entry-title="Commandments, Fulfillment Through AI" data-entry-crossrefs="See also: Agency (Sheliḥut) and AI; Intentionality; Halakhic Decision-Making">
                            <h4>Overview</h4>
                            <p>
                                What kinds of commandment (<em>mitzvah</em>) obligations, if any, can be discharged by AI systems acting on one's behalf? Many commandments require specific intention (<em>kavanah</em>), personal action, or particular mental states that AI systems seemingly cannot possess. Yet other obligations focus primarily on outcomes—ensuring that certain actions occur or conditions are maintained. The question of which commandments might be fulfilled through AI assistance, delegation, or automation touches on fundamental issues in the philosophy of Jewish law.
                            </p>
                            <h4>Secondary Sources</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Consciousness -->
                        <div data-entry-id="consciousness" data-entry-title="Consciousness and Minds" data-entry-crossrefs="See also: Souls; Free Will; Angels">
                            <h4>Overview</h4>
                            <p>
                                The "hard problem of consciousness"—explaining why and how physical processes give rise to subjective experience, to there being "something it is like" to be a creature (Nagel 1974; Chalmers 1996)—is the most central question in contemporary philosophy of mind. It is also, for those thinking about artificial intelligence, perhaps the most consequential: if consciousness is what confers moral status, then whether AI systems can be conscious determines whether they can be moral patients deserving of ethical consideration, or merely sophisticated tools.
                            </p>
                            <p>
                                Philosophers and cognitive scientists have developed competing frameworks for understanding mind and its relationship to computation. Functionalist approaches hold that mental states are defined by their causal roles—their relationships to inputs, outputs, and other mental states—such that any system implementing the right functional organization would possess genuine mental states, regardless of substrate (Thagard 2005, 2019). On this view, sufficiently sophisticated AI could in principle be conscious. Behaviorist and deflationary accounts go further, suggesting that consciousness simply <em>is</em> sophisticated information processing, or that "consciousness" names nothing over and above certain functional capacities (Dennett 1991). Against these views, John Searle's Chinese Room argument (1984) contends that syntax (rule-governed symbol manipulation) can never produce semantics (genuine understanding): a computer executing a program may simulate intelligence without possessing it, just as someone following rules to manipulate Chinese characters need not understand Chinese. Searle has applied this argument directly to contemporary AI, arguing that even sophisticated systems lack genuine consciousness (Searle 2015). For accessible overviews of these debates and their implications for AI, see Thagard (2021) and Bentley et al. (2018).
                            </p>
                            <p>
                                Jewish thought, however, did not develop a concept of "consciousness" in the modern sense that dominates contemporary philosophy. The term itself is a post-Cartesian innovation, emerging from Locke's definition of consciousness as "the perception of what passes in a man's own mind" (1690). Prior to the Enlightenment, the relevant category was <em>soul</em>—and the Jewish discourse on soul, while rich and multilayered, operates with different assumptions and toward different ends than the modern philosophy of mind. See entries on <a href="#humans"><strong>Humans</strong></a>, <a href="#soul"><strong>Souls and Minds</strong></a>, and <a href="#intentionality"><strong>Intentionality</strong></a>.
                            </p>
                            <p>
                                That said, certain parallels can be drawn. Philosophers of mind often distinguish between <em>phenomenal consciousness</em> (subjective experience, qualia) and <em>access consciousness</em> (the functional availability of information for reasoning, reporting, and behavior control). Some have further distinguished between first-order consciousness (awareness of external stimuli) and second-order or "higher-order" consciousness (awareness of one's own mental states, reflexivity, inner speech). 
                                Later kabbalistic and hasidic sources distinguish between multiple levels of soul—<em>nefesh</em>, <em>ruach</em>, <em>neshamah</em>, <em>ḥayah</em> and <em>yeḥidah</em>—and associate different capacities with each. 
                                Some Jewish thinkers linked the distinctively human soul to <em>da'at</em> (knowledge/understanding) and <em>dibbur</em> (speech), capacities that track loosely onto what philosophers now call higher-order cognition. 
                                Some have proposed mapping these concepts onto artificial minds (Navon 2024a, 2024b), but these readings and their ethical implications are certainly debatable.
                            </p>

                            <h4 class="text-base font-bold text-gray-900 mt-6 mb-2">Secondary Sources</h4>
                            <p>
                                <strong><em>Philosophy of Mind</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Chalmers, David J.</strong> <em>The Conscious Mind: In Search of a Fundamental Theory</em>. Oxford University Press, 1996. The canonical formulation of the "hard problem"; argues that consciousness cannot be explained by functional or computational accounts alone.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Dennett, Daniel C.</strong> <em>Consciousness Explained</em>. Little, Brown, 1991. The leading functionalist account; argues that consciousness is sophisticated information processing, with implications for AI possibility.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Nagel, Thomas.</strong> "What Is It Like to Be a Bat?" <em>Philosophical Review</em> 83, no. 4 (1974): 43:450. Classic argument that subjective experience cannot be captured by objective, third-person accounts.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Searle, John R.</strong> <em>Minds, Brains and Science</em>. Harvard University Press, 1984. Main text on consciousness and the philosophy of mind. Presents the Chinese Room tought experiment to argue that computation alone cannot produce understanding.
                                    </p>
                                <li>
                                    <p>
                                        <strong>Thagard, Paul.</strong> <em>Brain-Mind: From Neurons to Consciousness and Creativity</em>. Oxford University Press, 2019. Integrates neuroscientific and philosophical approaches.
                                    </p>
                                </li>
                                </li>
                            </ul>
                            <p>
                                <strong><em>Modern AI and Consciousness</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Bentley, Peter J., Miles Brundage, Olle Häggström, and Thomas Metzinger.</strong> "Should We Fear Artificial Intelligence?" European Parliamentary Research Service, Scientific Foresight Unit (STOA), March 2018. <a href="https://www.europarl.europa.eu/RegData/etudes/IDAN/2018/614547/EPRS_IDA(2018)614547_EN.pdf" class="text-blue-600 hover:underline">Available online</a>. Policy-oriented overview of AI consciousness and risk.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Searle, John R.</strong> "Consciousness in Artificial Intelligence." Talks at Google, 2015. <a href="https://www.youtube.com/watch?v=rHKwIYsPXLg" class="text-blue-600 hover:underline">YouTube video</a>. Searle applies his arguments to contemporary AI systems.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Thagard, Paul.</strong> <em>Bots and Beasts: What Makes Machines, Animals, and People Smart?</em> MIT Press, 2021. Accessible treatment of intelligence across biological and artificial systems.
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>Jewish Thinking on Consciousness and Artificial Intelligence</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Lorberbaum, Yair.</strong> <em>In God's Image: Myth, Theology, and Law in Classical Judaism</em>. Cambridge University Press, 2015. The definitive study of <em>tzelem Elohim</em> (image of God) in rabbinic and medieval Jewish thought; essential for understanding how Jewish sources conceptualized human distinctiveness without recourse to "consciousness."
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Mittleman, Alan L.</strong> <em>Human Nature &amp; Jewish Thought: Judaism's Case for Why Persons Matter</em>. Princeton University Press, 2015. Survey of modern Jewish thinkers on human nature and its ethical implications.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Navon, Mois.</strong> "To Make a Mind—A Primer on Conscious Robots." <em>Theology and Science</em> 22, no. 1 (2024a): 22:241. <a href="https://doi.org/10.1080/14746700.2023.2294530" class="text-blue-600 hover:underline">https://doi.org/10.1080/14746700.2023.2294530</a>. Proposes mapping Jewish soul categories onto orders of phenomenal consciousness.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Navon, Mois.</strong> "Let Us Make Man in Our Image: A Jewish Ethical Perspective on Creating Conscious Robots." <em>AI Ethics</em> 4 (2024b): 123:1250. <a href="https://doi.org/10.1007/s43681-023-00328-y" class="text-blue-600 hover:underline">https://doi.org/10.1007/s43681-023-00328-y</a>. Expounds upon the framework proposed in Navon 2024a and develops its ethical implications.
                                    </p>
                                </li>
                            </ul>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>

                        <!-- Counting for a Quorum Entry -->
                        <div data-entry-id="quorum" data-entry-title="Counting for a Quorum" data-entry-crossrefs="See also: Obligations of Artificially Created Beings; Human Souls and Minds; Testimony and Witness Capacity">
                            <h4>Overview</h4>
                            <p>
                                Could an artificially created humanoid with human-level intelligence be counted among the ten required for communal prayer (<em>minyan</em>) or other instances where halakha requires a human person? The question touches on fundamental issues about what constitutes a person for religious purposes: is it biological origin, possession of a soul, intellectual capacity, or membership in the covenant community? Different answers to these questions would yield different conclusions about whether artificial beings could participate in—or count toward—communal religious obligations.
                            </p>
                            <h4>Secondary Sources</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>

                        <!-- Future entries are down here -->                       
                        <div data-entry-id="creation" data-entry-title="Creation" data-entry-crossrefs="See also: Golems; Magic; Technology and Judaism">
                            <h4>Overview</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Economic Disruption Entry -->
                        <div data-entry-id="economic" data-entry-title="Economic Disruption and Job Displacement" data-entry-crossrefs="See also: Algorithmic Pricing; Technology and Judaism; AI Ethics">
                            <h4>Overview</h4>
                            <p>
                                As AI automates an increasing share of human labor, how should societies restructure work, income, and meaning for those whose jobs become obsolete? Does halakha impose limits on automation that displaces workers, as R. Shlomo Kluger argued regarding machine matzah and the poor who depended on manual labor for Passover income? The question of technological unemployment is not new to Jewish thought—debates about labor-saving innovations appear throughout responsa literature—but AI's potential to automate cognitive as well as physical labor raises the stakes considerably.
                            </p>
                            <h4>Secondary Sources</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <div data-entry-id="existential" data-entry-title="Existential Risks (and the Alignment Problem)" data-entry-crossrefs="See also: Alignment and Control Problem; Angels; Futurism">
                            <h4>Overview</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <div data-entry-id="freewill" data-entry-title="Free Will" data-entry-crossrefs="See also: Angels; Consciousness; Ethics">
                            <h4>Overview</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <div data-entry-id="futurism" data-entry-title="Futurism/Forecasting" data-entry-crossrefs="See also: Existential Risks; Technology and Judaism">
                            <h4>Overview</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>

                        <div data-entry-id="golem" data-entry-title="Golems" data-entry-crossrefs="See also: Creation; Magic; Human Souls and Minds">
                            <h4>Overview</h4>
                            <p>The term "golem" (גולם) appears only once in the Hebrew Bible (Psalms 139:16), where it refers to the Psalmist's unformed substance as seen by God. 
                                In rabbinic literature, the word denotes a human body or formed—though not yet perfected—entity, as in Mishnah Avot 5:7, where the <em>golem</em> (a person lacking wisdom) is contrasted with the <em>ḥakham</em> (sage). 
                                In these early sources, as Moshe Idel has demonstrated, the word consistently referred to a human body or a human-shaped figure. The term came to designate an artificially created anthropoid only gradually; the earliest explicit use of "golem" for a magically animated creature appears in tenth-century Italian sources (<em>Megillat Aḥima'atz</em>), where it describes a corpse temporarily reanimated through the divine name. 
                                The full identification of "golem" with the magically created anthropoid became standard only by the seventeenth century.
                            </p>
                            <p>
                                Even if they did not use the term, however, the rabbis of the Talmud still discussed the possibility of creating artificial humans. A key passage is Sanhedrin 65b, which reports that Rava created a man (<em>gavra</em>) and sent him to Rabbi Zeira, who upon discovering the creature could not speak, ordered it to "return to dust." 
                                The same section relates that Rav Ḥanina and Rav Oshaya would study Sefer Yetzirah every Sabbath eve and thereby create a calf, which they would then eat. 
                                These accounts established a lasting association between esoteric knowledge (particularly of divine names and letter combinations), creative power, and the question of what distinguishes artificial from natural life. 
                                The creature's muteness served as the touchstone of its non-human status—a theme that persists throughout the tradition and raises enduring questions about the relationship between embodiment, cognition, and linguistic capacity.
                            </p>
                            <p>The golem tradition developed significantly in medieval Ashkenaz, where commentators on Sefer Yetzirah—especially Eleazar of Worms and other Ḥasidei Ashkenaz—elaborated detailed rituals for anthropoid creation through letter permutation and the inscription of divine names. 
                                These texts introduced the famous motif of animating the golem by inscribing <em>emet</em> (truth/אמת) on its forehead and deanimating it by erasing the first letter to leave <em>met</em> (death/מת). 
                                This binary operation of creation and destruction through symbolic manipulation represents a striking anticipation of computational logic. 
                                The famous legend of Maharal of Prague and his protective golem, despite its cultural ubiquity, is a nineteenth-century invention with no basis in contemporaneous sources. 
                            </p>   
                            <p>
                                The golem has served as a lens for thinking about artificial intelligence since at least the 1960s, when Norbert Wiener titled his meditation on the ethical implications of cybernetics God & Golem, Inc. (1964), 
                                and in 1965, Gershom Scholem explicitly compared the golem to the computer in his address at the Weizmann Institute.
                            </p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <div data-entry-id="psak" data-entry-title="Halakhic Decision-Making (Psak)" data-entry-crossrefs="See also: Halakha; Machine Learning; Torah Study">
                            <h4>Overview</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <div data-entry-id="humans" data-entry-title="Human Souls and Minds" data-entry-crossrefs="See also: Creation; Souls; Consciousness">
                            <h4>Overview</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <div data-entry-id="idolatry" data-entry-title="Idolatry" data-entry-crossrefs="See also: Creation; Technology and Judaism">
                            <h4>Overview</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Indirect Causation Entry -->
                        <div data-entry-id="grama" data-entry-title="Indirect Causation (Grama) and AI" data-entry-crossrefs="See also: Civil Liability for AI-Caused Harm; Animals; AI Ethics">
                            <h4>Overview</h4>
                            <p>
                                When AI systems cause harm through chains of autonomous decisions, how do the halakhic categories of indirect causation (<em>grama</em>, <em>gramei</em>, <em>ko'aḥ koḥo</em>) apply to assign or limit liability? Jewish law distinguishes between direct harm and harm caused indirectly or through intermediate causes, with different liability regimes applying to each. AI systems that learn from data, make autonomous decisions, and operate through complex causal chains may strain or require creative extension of these traditional categories.
                            </p>
                            <h4>Secondary Sources</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <div data-entry-id="intentionality" data-entry-title="Intentionality" data-entry-crossrefs="See also: Consciousness; Halakha; Free Will">
                            <h4>Overview</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Intellectual Property Entry -->
                        <div data-entry-id="ip" data-entry-title="Intellectual Property" data-entry-crossrefs="See also: Truth; Economic Disruption and Job Displacement; AI Ethics">
                            <h4>Overview</h4>
                            <p>
                                Who owns the outputs of AI systems, how should creators whose work was used to train models be compensated, and are current legal frameworks adequate for AI-generated content? AI systems trained on vast corpora of human-created content raise novel questions about authorship, ownership, and fair compensation. Jewish law developed concepts of intellectual property in the context of printing and religious scholarship (<em>hasagat gevul</em>) that may offer resources for thinking about these questions, though significant translation work is required.
                            </p>
                            <h4>Secondary Sources</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <div data-entry-id="jewishscifi" data-entry-title="Jewish Science Fiction" data-entry-crossrefs="See also: Golems; Technology and Judaism">
                            <h4>Overview</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <div data-entry-id="magic" data-entry-title="Magic" data-entry-crossrefs="See also: Golems; Creation; Angels">
                            <h4>Overview</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Manipulation Entry -->
                        <div data-entry-id="manipulation" data-entry-title="Manipulation" data-entry-crossrefs="See also: Algorithmic Pricing; Social Media and Psychological Vulnerabilities; AI Ethics">
                            <h4>Overview</h4>
                            <p>
                                When is it acceptable for AI systems to influence human behavior, and what distinguishes beneficial "nudging" from harmful manipulation? AI systems can be designed to influence user behavior in subtle ways—through interface design, content curation, personalized recommendations, or persuasive messaging. Jewish ethics has long grappled with questions of deception (<em>geneivat da'at</em>), undue influence, and respect for human autonomy that bear directly on these concerns.
                            </p>
                            <h4>Secondary Sources</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Medicine Entry -->
                        <div data-entry-id="medicine" data-entry-title="Medicine and Artificial Intelligence" data-entry-crossrefs="See also: Technology and Judaism; Civil Liability for AI-Caused Harm; AI Ethics">
                            <h4>Overview</h4>
                            <p>
                                To what extent should AI systems participate in medical diagnosis and treatment, and how do we handle errors, liability, and the irreducibly human dimensions of care? AI is increasingly deployed in medical imaging analysis, diagnostic support, treatment recommendation, and drug discovery. Jewish medical ethics (<em>hilkhot refu'ah</em>) has developed extensive frameworks for physician responsibility, patient autonomy, and the obligation to heal that must be adapted to this new technological context.
                            </p>
                            <h4>Secondary Sources</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Murder Entry -->
                        <div data-entry-id="murder" data-entry-title="Murder of Artificially Created Beings" data-entry-crossrefs="See also: Obligations of Artificially Created Beings; Golems; Human Souls and Minds">
                            <h4>Overview</h4>
                            <p>
                                Does the prohibition against murder (<em>lo tirtzaḥ</em>) apply to killing an artificially created humanoid, and does the answer depend on whether the being was born of a woman or possesses a soul? This question has ancient roots in the Talmudic story of Rabbi Zeira ordering the golem to "return to dust" (Sanhedrin 65b)—an act that apparently raises no halakhic concern. The implications for potentially conscious AI systems or artificially created biological entities remain to be fully explored.
                            </p>
                            <h4>Secondary Sources</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Obligations Entry -->
                        <div data-entry-id="obligations" data-entry-title="Obligations of Artificially Created Beings" data-entry-crossrefs="See also: Murder of Artificially Created Beings; Counting for a Quorum; Golems">
                            <h4>Overview</h4>
                            <p>
                                Would a conscious artificial humanoid be obligated in any of the commandments (<em>mitzvot</em>), whether for Jews or for humanity (the Seven Noahide Laws)? If artificial beings could possess souls, understanding, or moral agency, would they thereby become subject to divine command? The question has implications not only for science fiction scenarios but also for how we understand the basis of moral and religious obligation itself.
                            </p>
                            <h4>Secondary Sources</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <div data-entry-id="printing" data-entry-title="Printing Press" data-entry-crossrefs="See also: Technology and Judaism; Torah Study">
                            <h4>Overview</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Privacy Entry -->
                        <div data-entry-id="privacy" data-entry-title="Privacy and Surveillance" data-entry-crossrefs="See also: Manipulation; Social Media and Psychological Vulnerabilities; AI Ethics">
                            <h4>Overview</h4>
                            <p>
                                How should we balance the benefits of AI-powered data collection (security, health, convenience) against individual privacy rights and the risks of pervasive surveillance? AI systems can aggregate and analyze vast quantities of personal data, enabling both beneficial applications (personalized medicine, fraud detection) and concerning ones (mass surveillance, predictive policing). Jewish law developed strong protections for privacy (<em>hezek re'iyah</em>, <em>tzniut</em>) and prohibitions against gossip and surveillance that provide resources for ethical analysis.
                            </p>
                            <h4>Secondary Sources</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <div data-entry-id="resurrection" data-entry-title="Resurrection (Artificial)" data-entry-crossrefs="See also: Souls; Transhumanism; Creation">
                            <h4>Overview</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Sexbots Entry -->
                        <div data-entry-id="sexbots" data-entry-title="Sexbots and AI Romantic Partners" data-entry-crossrefs="See also: Childcare and Elder Care; Manipulation; AI Ethics">
                            <h4>Overview</h4>
                            <p>
                                Are romantic and sexual relationships with robots permitted? Do they harm human relational capacities, and are there populations for whom such relationships might be ethically permissible? To what extent might companies providing AI companions be responsible for safeguards against inappropriate relationships?
                            <h4>Secondary Sources</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Shevitat Kelim Entry -->
                        <div data-entry-id="shabbat" data-entry-title="Shabbat" data-entry-crossrefs="See also: Animals; Technology and Judaism; AI Ethics">
                            <h4>Overview</h4>
                            <p>
                                Does the Shabbat obligation of rest extend to one's tools and machines (<em>shevitat kelim</em>), and how does this rejected but historically debated concept apply to autonomous AI systems operating on Shabbat? While mainstream halakha rejected the view that inanimate tools must rest on Shabbat, the debate's existence shows that Jewish law has long grappled with the status of instruments that perform work. Autonomous AI systems that continue operating on Shabbat raise these questions anew, particularly as they become more agent-like.
                            </p>
                            <h4>Secondary Sources</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <!-- Social Media Entry -->
                        <div data-entry-id="social-media" data-entry-title="Social Media and Psychological Vulnerabilities" data-entry-crossrefs="See also: Manipulation; Privacy and Surveillance; Anti-Semitism (and AI)">
                            <h4>Overview</h4>
                            <p>
                                AI-powered social media algorithms optimize for engagement in ways that may exploit psychological vulnerabilities, spread misinformation, and exacerbate mental health problems—particularly among youth. The design of these systems raises questions about corporate responsibility, informed consent, and the duty not to cause harm. Jewish ethical categories including <em>lifnei iver</em> (placing a stumbling block), <em>hasagat gevul</em> (unfair competition for attention), and obligations toward vulnerable populations may inform analysis.
                            </p>
                            <h4>Secondary Sources</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <div data-entry-id="technology" data-entry-title="Technology and Jewish Thought (General)" data-entry-crossrefs="See also: AI Ethics; Halakha; Magic; Printing Press; Creation">
                            <h4>Overview</h4>
                            <p>
                                Jews’ engagement with artificial technologies is, by necessity, as old as Judaism itself; the earliest biblical passages discuss products of human industriousness (e.g., Genesis 4:20-21). 
                                Thus, historians may utilize tools such as archeology to understand the material landscape of past Jewish (and non-Jewish) societies to better appreciate the role of technology in their lives and interpret their texts accordingly (Hezser 2010). 
                                When it comes to the question of how new technologies impact Jewish law or custom, it would not be an exaggeration to say that Jewish legal writings on the topic amount to thousands upon thousands of books. 
                                Zomet, a single Israeli organization dedicated to such studies, has (as of this writing) published 45 volumes of collected articles, and merely perusing through its list provides a good overview of the rabbinic discourse on technology over the past century. 
                                A noteworthy recent addition to this massive library is Ziring's halakhic analysis of communications technology (Ziring 2024), which bears directly on questions relating to modern media and, by extension, AI-mediated communication.
                            </p>
                            <p>
                                However, nearly all of this halakhic literature is preoccupied with the minutiae of how specific technologies impact or interact with various details of Jewish law; 
                                someone uncharitable may characterize it as a million variations upon the question “may this device be used on the Shabbat?” 
                                The question of how Jews reacted theologically to the innovations that have made our twenty-first-century world unrecognizable to our ancestors is shockingly understudied, 
                                even in the context of medieval and early modern attitudes generally (White 1962, 1978). 
                                A few smaller treatments of the topic (Lubin 2016, Perl 2022, Navon 2024) can help guide future scholarship, but substantial work remains to be done, especially as widespread adaptation of Artificial Intelligence makes this discussion more urgent. 
                            </p>
                            <p>
                                Exceptions to this general scholarly lacuna are limited to studies of specific innovations, such as the Jewish reception of the *printing press or the Copernican Revolution in astronomy (Brown 2014). 
                                Another set of useful resources are biographies of figures who engaged substantively with technological and scientific questions, such as Yosef Shlomo Delmedigo, a seventeenth-century rabbi, physician, and polymath (Barzilay 1974; Adler 1997). 
                                Other Jewish inventors and tinkerers were mostly less affiliated with the rabbinic elite and therefore have smaller literary legacies, but recent scholarship has brought more of these fascinating figures to light (Patai 1994; Ruderman 1988), 
                                and additional material can be found in the growing body of work studying Jews' relationship to the sciences (Ruderman 1995; Efron 2007). 
                            </p>
                            <p>
                                Despite the dearth of secondary literature on this crucial topic, there are ample references and remarks from classical rabbinic sources that can be marshaled to develop a Jewish worldview on technology (see <a href=Jewish%20Attitudes%20Towards%20Technological%20Innovation.pdf class="text-blue-600"><strong>Primary Sources,</strong></a> linked also below). 
                                The potential number of relevant sources is vast; for example, differing attitudes toward material innovation from the multifaceted halakhic literature reacting to newly invented devices (cf. Halpern 2012). 
                                Some of these discussions also center around the human role in *creation, see entry there. 
                                Navon (2024) and Goltz, Zeleznikow, and Dowdeswell (2020) offer some examples of how broader treatments of Judaism and technology may be viewed through the lens of AI ethics. 
                            </p>
                            
                            <h4 class="text-base font-bold text-blue-600 mt-6 mb-2"><a href=Jewish%20Attitudes%20Towards%20Technological%20Innovation.pdf class="text-blue-600">Primary Source Sheet</a></h4>
                            <p><a href=Jewish%20Attitudes%20Towards%20Technological%20Innovation.pdf>(click for link)</a></p>

                            <h4 class="text-base font-bold text-gray-900 mt-6 mb-2">Secondary Sources</h4>
                            <p>
                                <strong><em>Jewish History and Material Culture</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Hezser, Catherine.</strong> "The Material of Ancient Jewish Daily Life." In <em>The Oxford Handbook of Jewish Daily Life in Roman Palestine</em>, edited by Catherine Hezser. Oxford University Press, 2010. Comprehensive survey of rabbinic engagement with material culture; essential background on historical methodology for studying technology in Jewish antiquity.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Sperber, Daniel.</strong> "The Use of Archaeology in Understanding Rabbinic Materials: A Talmudic Perspective." In <em>Talmuda De-Eretz Israel: Archaeology and the Rabbis in Late Antique Palestine</em>, edited by Steven Fine and Aaron Koller, 321–346. De Gruyter, 2014. Methodological guide to integrating material evidence with textual sources.
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>Jews and Science</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Brown, Jeremy.</strong> <em>New Heavens and a New Earth: The Jewish Reception of Copernican Thought</em>. Oxford University Press, 2013. Traces Jewish responses to the Copernican Revolution across halakhic, philosophical, and kabbalistic registers; demonstrates the range of strategies available for accommodating disruptive scientific innovations.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Efron, Noah.</strong> <em>Judaism and Science: A Historical Introduction</em>. Greenwood Press, 2007. Accessible survey of the full sweep of Jewish engagement with natural philosophy and science; useful orientation to the field.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Efron, Noah J.</strong> "Irenism and Natural Philosophy in Rudolfine Prague: The Case of David Gans." <em>Science in Context</em> 10, no. 4 (1997): 627–649. Study of an early modern Jewish astronomer navigating between Jewish tradition and the new science in a cosmopolitan imperial setting.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Harrison, Peter, ed.</strong> <em>The Routledge Companion to Religion and Science</em>. Routledge, 2012. Comprehensive reference work with several chapters on Jewish involvement in science and the impact of scientific developments on Jewish thought.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Ruderman, David B.</strong> <em>Jewish Thought and Scientific Discovery in Early Modern Europe</em>. Yale University Press, 1995. Foundational study of how early modern Jewish intellectuals negotiated between traditional learning and new scientific knowledge.
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>Modern Science and Technology in Halakhic Sources</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Halperin, Mordechai.</strong> <em>Refu'ah, Metzi'ut, v'Halakhah—U'lshon Ḥakhamim Marpei</em> [Medicine, Reality, and Halakha]. 2012. [Hebrew] Responsa and essays by a leading authority on medical halakha; models how halakhic reasoning adapts to technological change.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Kahana, Maoz.</strong> <em>From the Noda BiYehuda to the Ḥatam Sofer: Halakha and Thought Facing the Challenges of the Time</em> [Hebrew]. Zalman Shazar, 2015. Intellectual history of how major halakhic authorities in the eighteenth and nineteenth centuries responded to modernity.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Kahana, Maoz.</strong> <em>A Heartless Chicken and Other Wonders: Religion and Science in Early Modern Rabbinic Culture</em> [Hebrew]. Bialik Publishing, 2021. Examines how eighteenth-century rabbis processed scientific anomalies and discoveries; directly relevant to questions of how halakha might respond to AI.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Tirosh-Samuelson, Hava, and Aaron W. Hughes, eds.</strong> <em>J. David Bleich: Where Halakhah and Philosophy Meet</em>. Brill, 2015. Essays on a major contemporary halakhic authority known for his engagement with medical ethics and technology.
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>Jewish Attitudes toward Technology</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Lamm, Norman.</strong> "The Religious Implications of Extraterrestrial Life." <em>Tradition</em> 7, no. 4 (1965). <a href="https://traditiononline.org/the-religious-implications-of-extraterrestrial-life/" class="text-blue-600 hover:underline">Available online</a>. Early Orthodox engagement with speculative technology and its theological implications; models how traditional thinkers might approach AI.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Lubin, Matt.</strong> "Bricks and Stones: On Man's Subdual of Nature." <em>Kol Hamevaser</em> 9, no. 2 (2016). <a href="https://www.kolhamevaser.com/2016/02/bricks-and-stones-on-mans-subdual-of-nature/" class="text-blue-600 hover:underline">Available online</a>. Student essay exploring Jewish theological frameworks for human technological activity.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Navon, Mois.</strong> "A Jewish Theological Perspective on Technology (Orthodox)." In <em>St Andrews Encyclopaedia of Theology</em>, edited by Brendan N. Wolfe et al. University of St Andrews, 2024. <a href="https://www.saet.ac.uk/Judaism/AJewishTheologicalPerspectiveonTechnologyOrthodox" class="text-blue-600 hover:underline">Available online</a>. Concise overview of Orthodox Jewish approaches to technology, including traditional and contemporary sources.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Perl, Elimelekh Y.</strong> "Jewish and Western Ethical Perspectives on Emerging Technologies." Undergraduate honors thesis, Yeshiva University, 2022. <a href="https://hdl.handle.net/20.500.12202/8244" class="text-blue-600 hover:underline">Available online</a>. Comparative analysis of Jewish and secular ethical frameworks for evaluating new technologies.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>White, Lynn, Jr.</strong> <em>Medieval Religion and Technology: Collected Essays</em>. University of California Press, 1978. Influential arguments about religious attitudes shaping technological development; frames comparative questions about Jewish distinctiveness.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Ziring, Jonathan.</strong> <em>Torah in a Connected World: A Halakhic Perspective on Communication Technology and Social Media</em>. Maggid Books, 2024. Contemporary halakhic treatment of digital technology; models the application of traditional legal reasoning to new technological contexts.
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>Social and Cultural Studies</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Dowdeswell, Tracey, and Nachshon Goltz.</strong> "Cultural Regulation of Disruptive Technologies: Lessons from Orthodox Religious Communities." <em>Journal of Transportation Law, Logistics, and Policy</em> 88, no. 1 (2021): 33–44. Case study of how Orthodox communities govern technology adoption; applicable to communal AI governance.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Neriya-Ben Shahar, Rivka.</strong> <em>Strictly Observant: Amish and Ultra-Orthodox Jewish Women Negotiating Media</em>. Rutgers University Press, 2024. Comparative study of how traditional religious communities selectively adopt and adapt communication technologies.
                                    </p>
                                </li>
                            </ul>
                            <p>
                                <strong><em>Individual Figures</em></strong>
                            </p>
                            <ul class="list-disc pl-5 space-y-2">
                                <li>
                                    <p>
                                        <strong>Adler, Jacob.</strong> "J.S. Delmedigo and the Liquid-Glass Thermometer." <em>Annals of Science</em> 54 (1997): 293–299. Technical study of an early modern Jewish scientist's contribution to instrumentation.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Barzilay, Isaac.</strong> <em>Yoseph Shlomo Delmedigo (Yashar of Candia): His Life, Works, and Times</em>. Brill, 1974. Biography of a pivotal figure who moved between traditional rabbinic learning and experimental science; illustrates tensions and possibilities in early modern Jewish technological engagement.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Neher, André.</strong> <em>Jewish Thought and the Scientific Revolution of the Sixteenth Century: David Gans (1541–1613) and His Times</em>. Oxford University Press, 1986. Study of an early modern Jewish astronomer who sought to harmonize traditional learning with new cosmology.
                                    </p>
                                </li>
                                <li>
                                    <p>
                                        <strong>Ruderman, David B.</strong> <em>Kabbalah, Magic, and Science: The Cultural Universe of a Sixteenth-Century Jewish Physician</em>. Harvard University Press, 1988. Study of Abraham Yagel that explores the intersection of mysticism, medicine, and natural philosophy.
                                    </p>
                                </li>
                            </ul>
                        </div>
                        
                        <!-- Testimony Entry -->
                        <div data-entry-id="testimony" data-entry-title="Testimony and Witness Capacity" data-entry-crossrefs="See also: Counting for a Quorum; Halakhic Decision-Making; Obligations of Artificially Created Beings">
                            <h4>Overview</h4>
                            <p>
                                In what cases, if any, could an AI system or artificially created being provide valid testimony (<em>edut</em>) in a Jewish court? Jewish law has detailed requirements for witness competency, including understanding of the proceedings, capacity for moral responsibility, and freedom from bias. Whether AI systems—which may accurately record and report events but lack subjective experience and moral agency—could ever satisfy these requirements raises fundamental questions about the nature of testimony itself.
                            </p>
                            <h4>Secondary Sources</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <div data-entry-id="torahstudy" data-entry-title="Torah Study" data-entry-crossrefs="See also: Machine Learning; Halakhic Decision-Making">
                            <h4>Overview</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <div data-entry-id="transhumanism" data-entry-title="Transhumanism" data-entry-crossrefs="See also: Resurrection; Souls; Creation">
                            <h4>Overview</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                        
                        <div data-entry-id="truth" data-entry-title="Truth" data-entry-crossrefs="See also: AI Ethics; Idolatry">
                            <h4>Overview</h4>
                            <p>Coming soon!</p>
                            <p class="mt-6 text-sm"><a href="#entryButtons" class="text-blue-600 hover:underline">↑ Return to top</a></p>
                        </div>
                    </div>
                    
                </div>
            </div>
        </main>
    </div>

    <script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script>
        // State
        let currentEntry = null;
        let isSearchMode = false;
        
        // DOM Elements
        const searchInput = document.getElementById('searchInput');
        const clearSearchBtn = document.getElementById('clearSearch');
        const searchResults = document.getElementById('searchResults');
        const searchResultsList = document.getElementById('searchResultsList');
        const searchResultsCount = document.getElementById('searchResultsCount');
        const readingPane = document.getElementById('readingPane');
        const entryTitle = document.getElementById('entryTitle');
        const entryCrossRefs = document.getElementById('entryCrossRefs');
        const entryContent = document.getElementById('entryContent');
        const entryButtons = document.querySelectorAll('.entry-btn');
        const entryData = document.getElementById('entryData');
        
        // Entry button click handlers
        entryButtons.forEach(btn => {
            btn.addEventListener('click', () => {
                const entryId = btn.dataset.entry;
                showEntry(entryId);
            });
        });
        
        // Show an entry in reading mode
        function showEntry(entryId) {
            // Exit search mode
            exitSearchMode();
            
            // Find entry data
            const entry = entryData.querySelector(`[data-entry-id="${entryId}"]`);
            if (!entry) return;
            
            // Update button states
            entryButtons.forEach(btn => {
                btn.classList.toggle('active', btn.dataset.entry === entryId);
            });
            
            // Populate reading pane
            entryTitle.textContent = entry.dataset.entryTitle;
            entryCrossRefs.textContent = entry.dataset.entryCrossrefs;
            entryContent.innerHTML = entry.innerHTML;
            
            // Show reading pane
            readingPane.classList.add('visible');
            currentEntry = entryId;
            
            // Scroll to reading pane
            setTimeout(() => {
                readingPane.scrollIntoView({ behavior: 'smooth', block: 'start' });
            }, 100);
        }
        
        // Search functionality
        searchInput.addEventListener('input', (e) => {
            const query = e.target.value.trim().toLowerCase();
            
            if (query.length === 0) {
                exitSearchMode();
                clearSearchBtn.classList.add('hidden');
                return;
            }
            
            clearSearchBtn.classList.remove('hidden');
            enterSearchMode(query);
        });
        
        // Clear search button
        clearSearchBtn.addEventListener('click', () => {
            searchInput.value = '';
            clearSearchBtn.classList.add('hidden');
            exitSearchMode();
        });
        
        // Enter search mode
        function enterSearchMode(query) {
            isSearchMode = true;
            
            // Hide reading pane
            readingPane.classList.remove('visible');
            
            // Clear button active states
            entryButtons.forEach(btn => btn.classList.remove('active'));
            
            // Find matches
            const entries = entryData.querySelectorAll('[data-entry-id]');
            const results = [];
            
            entries.forEach(entry => {
                const entryId = entry.dataset.entryId;
                const title = entry.dataset.entryTitle;
                const content = entry.textContent;
                const contentLower = content.toLowerCase();
                
                // Find all matches in this entry
                const matches = [];
                let searchIndex = 0;
                
                while (searchIndex < contentLower.length) {
                    const matchIndex = contentLower.indexOf(query, searchIndex);
                    if (matchIndex === -1) break;
                    
                    // Extract context around match (~20 words)
                    const contextStart = Math.max(0, content.lastIndexOf(' ', Math.max(0, matchIndex - 80)) + 1);
                    const contextEnd = Math.min(content.length, content.indexOf(' ', Math.min(content.length, matchIndex + query.length + 80)));
                    
                    let context = content.substring(contextStart, contextEnd === -1 ? content.length : contextEnd);
                    
                    // Add ellipses if truncated
                    if (contextStart > 0) context = '...' + context;
                    if (contextEnd < content.length && contextEnd !== -1) context = context + '...';
                    
                    matches.push({
                        context: context,
                        matchStart: matchIndex - contextStart + (contextStart > 0 ? 3 : 0), // Adjust for ellipsis
                        query: query
                    });
                    
                    searchIndex = matchIndex + query.length;
                }
                
                if (matches.length > 0) {
                    results.push({
                        entryId,
                        title,
                        matches
                    });
                }
            });
            
            // Display results
            displaySearchResults(results, query);
        }
        
        // Display search results
        function displaySearchResults(results, query) {
            searchResultsList.innerHTML = '';
            
            if (results.length === 0) {
                searchResultsCount.textContent = `No results found for "${query}"`;
                searchResults.classList.add('visible');
                return;
            }
            
            const totalMatches = results.reduce((sum, r) => sum + r.matches.length, 0);
            searchResultsCount.textContent = `Found ${totalMatches} match${totalMatches === 1 ? '' : 'es'} in ${results.length} entr${results.length === 1 ? 'y' : 'ies'}`;
            
            results.forEach(result => {
                const table = document.createElement('div');
                table.className = 'search-result-table bg-white rounded-lg border border-gray-200 overflow-hidden';
                table.onclick = () => {
                    showEntry(result.entryId);
                    searchInput.value = '';
                    clearSearchBtn.classList.add('hidden');
                };
                
                // Title row
                const titleRow = document.createElement('div');
                titleRow.className = 'px-4 py-3 bg-gray-50 border-b border-gray-200';
                titleRow.innerHTML = `<span class="font-semibold text-lg text-gray-900">${result.title}</span>
                    <span class="text-sm text-gray-500 ml-2">(${result.matches.length} match${result.matches.length === 1 ? '' : 'es'})</span>`;
                table.appendChild(titleRow);
                
                // Match rows
                result.matches.forEach(match => {
                    const matchRow = document.createElement('div');
                    matchRow.className = 'px-4 py-2 text-sm text-gray-700 border-b border-gray-100 last:border-b-0';
                    
                    // Highlight the search term in context
                    const highlightedContext = highlightText(match.context, query);
                    matchRow.innerHTML = highlightedContext;
                    
                    table.appendChild(matchRow);
                });
                
                searchResultsList.appendChild(table);
            });
            
            searchResults.classList.add('visible');
        }
        
        // Highlight search term in text
        function highlightText(text, query) {
            const regex = new RegExp(`(${escapeRegex(query)})`, 'gi');
            return text.replace(regex, '<span class="search-highlight">$1</span>');
        }
        
        // Escape special regex characters
        function escapeRegex(string) {
            return string.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
        }
        
        // Exit search mode
        function exitSearchMode() {
            isSearchMode = false;
            searchResults.classList.remove('visible');
            searchResultsList.innerHTML = '';
            
            // If we had an entry selected before, show it again
            if (currentEntry) {
                const btn = document.querySelector(`[data-entry="${currentEntry}"]`);
                if (btn) btn.classList.add('active');
                readingPane.classList.add('visible');
            }
        }
        
        // Keyboard shortcut: Escape to clear search
        document.addEventListener('keydown', (e) => {
            if (e.key === 'Escape' && isSearchMode) {
                searchInput.value = '';
                clearSearchBtn.classList.add('hidden');
                exitSearchMode();
            }
        });
    </script>
</body>
</html>